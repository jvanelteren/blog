{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /2020/07/26/housing\n",
    "author: Jesse van Elteren\n",
    "badges: true\n",
    "branch: master\n",
    "categories: [house, pricing, prediction]\n",
    "date: '2020-07-26'\n",
    "description: Top 3% in a data science competition\n",
    "image: housing.png\n",
    "output-file: 2020-07-26-housing.html\n",
    "title: Predicting the value of a house\n",
    "toc: false\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](housing.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently I’ve made my way into Kaggle. If it’s new for you, I highly recommend checking it out. Kaggle is a platform where organizations host data science competitions. They come up with a data science challenge, make the data available to Kaggle users, and many data scientist worldwide compete to get the highest score on the leaderboard. After a defined period the competition ends and the winner is awarded with a (monetary) price.\n",
    "\n",
    " \n",
    "\n",
    "Participants also share their code (kernels), and have discussions on the data. This makes it an excellent platform to learn. The competitions can be a bit intimidating, since it can have extremely large datasets (100GB upwards), the objectives can be challenging (imaging, audio, text, combinations) and figuring out how to submit is not always trivial. But of course you can start with simpler competitions such as the [classic Titanic example](https://www.kaggle.com/c/titanic).\n",
    "\n",
    " \n",
    "\n",
    "Since I’m quite familiar with tabular data I decided to give the housing competition a try. [The training data]( https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) consists of many features describing about 1500 houses and their selling price. After numerous experiments I ended up with a top 3% score on the leaderboard before throwing in the proverbial towel. The rush of inching up the leaderboard made it a great experience!\n",
    "\n",
    " \n",
    "\n",
    "Afterwards I wrote about the [main insights, learnings and questions](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/discussion/170472)\n",
    "\n",
    "Next up: probably a imaging competition with Pytorch or fast.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2020-09-12-redblacktree.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
