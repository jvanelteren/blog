[
  {
    "objectID": "posts/turnen/2021-04-29-turnen.html",
    "href": "posts/turnen/2021-04-29-turnen.html",
    "title": "Turnonderzoek op het journaal",
    "section": "",
    "text": "Op het NOS journaal: tweederde van turners heeft te maken met grensoverschrijdend gedrag. Als vader met een meisje op turnen krab je je dan toch even achter de oren‚Ä¶ Maar, de interesse was gewekt en voor het lidmaatschap op te zeggen ben ik toch even het ruim 400 pagina‚Äôs dikke rapport ingedoken. Uiteraard met de databril op. En dan schrik je toch wel, maar vooral van de eenzijdige journalistiek‚Ä¶\nWaar komt die tweederde vandaan? Het journaal meldt dat het hierbij gaat om oud-sporters en actieve. Dat klopt niet, het gaat om oud sporters (van voor 2014). Deze konden een vragenlijst invullen op de website van de turnbond. De turnbond beschikte niet over de emailadressen van deze turners, dus de participanten moeten op een andere manier hun weg naar de website hebben moeten vinden. 282 deelnemers hebben de vragenlijst ingevuld. Ter referentie, in 2014 had de turnbond 241.435 leden. De onderzoekers melden zelf ook dat de resultaten niet representatief zijn en dat er geen generaliserende conclusies kunnen worden getrokken over de gehele gymsport.\nEr treedt bij dit onderzoek een dubbel selectie-effect op: * Mensen met een sterke mening over het onderwerp zullen de vragenlijst eerder invullen. Vergelijk het met een onderzoek over geluidsoverlast. Welke mensen zullen hierbij reageren, degene die geluidsoverlast ervaren of niet? Om dit effect te verminderen was een alternatieve aanpak geweest om niet aan te kondigen dat dit onderzoek over GOG ging. Maar dat heeft ook weer zo z‚Äôn nadelen. * 80% van de deelnemers geeft aan (semi)topsport te hebben beoefend. Van deze oud-topsporters geeft 85% aan met grensoverschrijdend gedrag te maken te hebben gehad. Bij de semi-topsporters is dit 58% en bij de breedtesporters 35%. Het hoge aandeel van topsporters in de respondenten trekt het gemiddelde omhoog naar tweederde. Beide effecten werken vertekenend als je een conclusie wilt trekken over de gehele turnsport. De auteurs benoemen het mogelijke selectie-effect.\nEr zijn ook vragenlijsten per email verstuurd, van de 180.000 turners waarvan gegevens beschikbaar waren zijn alle (semi) topsporters van na 2014 aangeschreven (8147) en 5% (7136) van de overige leden. Ongeveer 18% reageerde. Dit is een ietwat magere respons. Hieronder een gedeelte van de infographic van het rapport, deze geeft het verschil weer tussen de ervaringen van topsporters (60-70% te maken met GOG) en recreatieve sporters (15% te maken met GOG).\nHet aantal respondenten vanuit de recreatieve groep is erg klein, bijvoorbeeld 21 respondenten waren volwassen recreatieve sporters. In werkelijkheid turnt 73% van de turners op recreatief niveau, niet 3% zoals bij de volwassen respondenten. Recreatieve sporters zijn dus enorm ondervertegenwoordigd in de steekproef. Wederom het selectie-effect. De onderzoekers geven aan dat ‚Äòde omvang van grensoverschrijdend gedrag vrijwel niet betrouwbaar is vast te stellen‚Äô.\n\nEen heel negatief beeld dus op het journaal. Met betrekking tot de breedtesport kan je nauwelijks cijfermatige conclusies trekken, terwijl het wel wordt gepresenteerd als de turnsport als geheel. Bij wedstrijdsporters is er meer zekerheid, maar blijft het selectie-effect een grote onzekerheid. Maar het genuanceerde verhaal paste natuurlijk niet in het journaal.\nDan is er ook nog een soort positief nieuws, er wordt onderzoek geciteerd uit 2020, door NOC/NSF gepresenteerd als representatief (n=5.000). Turnen staat bij een vergelijkend onderzoek laag in de middenmoot van sporten waar mensen grensoverschrijdend gedrag hebben meegemaakt (voetbal, handbal, hockey, korfbal scoren veel hoger). Bij seksueel grensoverschrijdend gedrag staat turnen nog lager, ongeveer gelijk met ‚Äòschaken‚Äô. Zie onder de grafiek over emotioneel grensoverschrijdend gedrag uit dat onderzoek. Hierbij is geen onderscheid gemaakt tussen top- en recreatiesport.\n\nMeer positief nieuws: van de respondenten geven de volwassenen het turnen gemiddeld een 8 (33% geeft een 9 of 10) en de minderjarigen met een 8,5 (54% geeft een 9 of 10). Deze score ligt bij de topsporters wat lager dan bij de recreanten. Maar komt dat door GOG of doordat topsport als minder leuk wordt ervaren? Het zou interessant zijn om deze getallen nog uit te splitsen in groepen die wel/niet GOG te maken hebben gehad. Dan kan je misschien iets zeggen over de impact van GOG/topsport op turnplezier. Hieronder de grafiek van minderjarige respondenten.\n\nDan tenslotte: ik heb echt alleen naar de cijfers gekeken, dit doet niets af aan de ernstige ervaringen die turners in kwestie hebben meegemaakt. Dit is nooit acceptabel en werken aan verbetering van de sport is altijd goed.\nZolang m‚Äôn dochter het leuk vindt (en nog geen topsporter is) ga ik in elk geval met gerust hart en veel plezier naar de ü§∏‚Äç‚ôÄÔ∏èturntrainingü§∏‚Äç‚ôÇÔ∏è!"
  },
  {
    "objectID": "posts/redblack/2020-09-12-redblacktree.html",
    "href": "posts/redblack/2020-09-12-redblacktree.html",
    "title": "Red-Black trees",
    "section": "",
    "text": "After playing around with red-black trees for some time, I‚Äôve grown to really like them, but also hate them at the same time! I‚Äôll explain in this blog why. To understand what a red-black tree is, we‚Äôll first have to touch upon the concept of a binary search tree. The binary search tree is a method of ordering items that can be compared to each other. The easiest example is of course numbers (1 &lt; 2), other object such as letters (a &lt; b) or words (short &lt; longerword) can also be compared.\nA binary tree is very simple and I had fun making one with my six year old daughter. She came up with a list of numbers and together we added them to the tree. The root of the tree is the first item you start with. Next, to add another item you simply check if the item is smaller or larger than the root. If it‚Äôs smaller it gets stored into the left branch, if it‚Äôs larger it goes to the right branch. A node in the tree can have only one branch on each side. Therefore the tree will have to get deeper when more nodes are added. As an example, a tree with 3 layers holds a maximum of 1+2+4 = 7 nodes. Below an example, where it takes three steps to reach 5,14 and 55 and four steps to reach 62 and 66. These nodes are the edge of the tree and are called leaves.\n\n\n\n\n\n\n\n\n\nThe advantage of binary search trees is that the items are ordered. For example, you can easily lookup the minimum (just always go left from the root). But also finding an item can be very quick, which is expressed by the number of steps from the root. It makes sense, if you are interested in the left side of the tree, you no longer need to search the right side.\nBut think about a scenario where you insert numbers in order, ascending. The tree would only have right branches! This effectively means you are just storing a list. Now for a small tree (as the one below), that is no problem, but if you are storing a million items this way, you would have to search a million items before inserting the next number. If the tree would have been balanced, it would only take about 20 steps from the root to any leaf (1 million log base 2).\n\n\n\n\n\n\n\n\n\nThis is where red-black trees come in. They are self-balancing to solve the above problem. In a red-black tree, items are colored in two colors. You‚Äôve guessed it, red or black. There are a couple of rules:\n\nThe root is always black\nWhile going from root to any leaf, you‚Äôll never pass two consecutive red items\nThe amount of black items you pass while going to an end of the tree is the same for each leaf of the tree.\n\nTo preserve these properties insertion and removal can require certain operations, such as recoloring certain items, or rotating part of the tree. And this is where my love and hate comes in. It‚Äôs awesome to see the different shapes the tree can take while balancing. Even the root of the tree can change in the process. A couple of examples:\n\n\n\n\n\n\n\n\n\nIn the above figure, numbers 0 to 10 were inserted in order. The graph shows that the redblack tree has been rotated to now have 3 as root (no longer the 0 it started with initially). Also the paths from the root (3) to the leaves (0,2,4,6,8 and 9) all cross exactly 3 black nodes!\nIf we insert 50 items in order, a nice balanced tree appears\n\nto_insert = list(range(50))\nRBTree(to_insert,silent=True).draw()\n\n\n\n\n\n\n\n\nWhen we randomize the insertion order a completely different tree arises, but still it‚Äôs nicely balanced.\n\nrandom.shuffle(to_insert)\nRBTree(to_insert,silent=True).draw()\n\n\n\n\n\n\n\n\nI think this looks elegant. However, it‚Äôs known that redblack trees can be difficult to implement and indeed it‚Äôs been an absolute pain to code the algorithms, with some difficult debugging to take care of all the edge cases to make sure the code runs correctly. More detailes of all the cases you can encounter at Wikipedia. I‚Äôve gained new appreciation for programming concepts such as unit testing, refactoring, and plain old careful reading of the specification. Seeing it work has made this project worth it!\nAfter some reading, I‚Äôve also come across the treap (tree-heap), which is basically using random numbers to make the tree structure as if the items would have been inserted in random order. Which will make the tree balanced with a high probablility.\nTo illustrate the randomness, I‚Äôve twice made a treap with 50 items inserted in order. The resulting trees are different, which does not happen with red-black trees when the insertion order is the same. Treaps look much different then the red-black trees as well.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTreaps are much simpler to implement and outperform red-black trees on insertion, search and deletion, but due to their randomized nature are less consistent. Also red-black trees look nicer in my opinion.\nThat‚Äôs it, hope you enjoyed it this exploration of trees!\n\n\n\n\n\n\nTip\n\n\n\nThis page has a nice animation how red-black trees are build. Additionally, Wikipedia has more information about binary search trees, red black trees and treaps"
  },
  {
    "objectID": "posts/moties2023/2023-08-26-kamermotieseda.html",
    "href": "posts/moties2023/2023-08-26-kamermotieseda.html",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "",
    "text": "De verkiezingen komen eraan, en de Tweede Kamer heeft een open data portaal. Daar heb ik weer fijn gebruik van gemaakt en alle moties vanaf 2009 gedownload, t/m eind augustus 2023. Het zijn er om precies te zijn 39245. In dit blog kijk ik of er interessante inzichten uit te halen zijn."
  },
  {
    "objectID": "posts/moties2023/2023-08-26-kamermotieseda.html#ontwikkeling-van-het-aantal-moties",
    "href": "posts/moties2023/2023-08-26-kamermotieseda.html#ontwikkeling-van-het-aantal-moties",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Ontwikkeling van het aantal moties",
    "text": "Ontwikkeling van het aantal moties\n\n\n\n\n\n\n\n\nHet aantal moties stijgt, met name het aantal aangenomen moties.\n\nWe kunnen ook histogrammen maken per kabinetsperiode. Hierin kunnen we zien hoeveel stemmen moties hebben gekregen.\n\n\n\n\n\n\n\n\n\nIn de histogrammen gaat het vooral om de verdeling van de moties tijdens de kamerperiodes. De rode moties hebben het niet gehaald, de groene wel.\n\nRutte I: relatief veel moties die het nipt niet haalden\nRutte II: veel afgewezen moties\nRutte III: hele grote piek in het aantal unaniem aangenomen moties"
  },
  {
    "objectID": "posts/moties2023/2023-08-26-kamermotieseda.html#welke-partij-is-de-tegenpartij",
    "href": "posts/moties2023/2023-08-26-kamermotieseda.html#welke-partij-is-de-tegenpartij",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Welke partij is de ‚Äòtegenpartij‚Äô?",
    "text": "Welke partij is de ‚Äòtegenpartij‚Äô?\n\n\n\n\n\n\n\n\nDe oppositie steunt de meeste moties, terwijl de regering vaak tegen stemt."
  },
  {
    "objectID": "posts/moties2023/2023-08-26-kamermotieseda.html#welke-partijen-dienen-het-meeste-moties-in-en-hoe-succesvol-zijn-ze",
    "href": "posts/moties2023/2023-08-26-kamermotieseda.html#welke-partijen-dienen-het-meeste-moties-in-en-hoe-succesvol-zijn-ze",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Welke partijen dienen het meeste moties in en hoe succesvol zijn ze?",
    "text": "Welke partijen dienen het meeste moties in en hoe succesvol zijn ze?\n\n\n\n\n\n\n\n\nIn bovenstaande grafiek zijn de partijen op elkaar gestapeld. Het aantal moties per jaar is sterk gestegen. De volgorde van de partijen is gebaseerd op vergelijkbaar stemgedrag, daar kom ik later op terug.\n\n\n\n\n\n\n\n\nDeze visualisatie geeft weer hoeveel moties (niet) succesvol zijn ingediend. Je ziet bijvoorbeeld PVV en SP als partijen met veel moties, maar weinig succesvolle. Ook worden de moties van regeringspartijen vaker aangenomen. Dit komt natuurlijk doordat ze met de regeringspartijen een meerderheid hebben. Laten we nu kijken hoe deze grafiek eruit ziet per zetel, als een soort ‚Äòproductiviteit per zetel‚Äô.\n\n\n\n\n\n\n\n\nOpvallend is het hoge aantal moties van BBB per zetel. Bij de VVD en D66 valt het lage aantal moties per zetel op. Dit zijn natuurlijk ook de regeringspartijen met het grootste aantal zetels, terwijl BBB momenteel 1 zetel heeft."
  },
  {
    "objectID": "posts/moties2023/2023-08-26-kamermotieseda.html#wie-zijn-de-motiekanonnen-van-de-tweede-kamer",
    "href": "posts/moties2023/2023-08-26-kamermotieseda.html#wie-zijn-de-motiekanonnen-van-de-tweede-kamer",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Wie zijn de ‚Äòmotiekanonnen‚Äô van de Tweede Kamer?",
    "text": "Wie zijn de ‚Äòmotiekanonnen‚Äô van de Tweede Kamer?\nWie is nu het meest ‚Äòsuccesvolle‚Äô kamerlid?\n\nDe Producent: Wiebren van Haga diende maar liefst 191 moties in per jaar, hiermee blijft hij Caroline vd Plas nipt voor (183 per jaar).\nDe Winnaar: Pieter Grinwis van de ChristenUnie. Met 85 aangenomen moties het succesvolst. Caroline vd Plas (BBB) staat op plek twee met 66 successen per jaar, op de voet gevolgd door Stephan van Baarle (DENK) (44).\nDe Samenwerker: Kijken we naar de politicus die het meeste moties heeft mede-ingediend staat Caroline vd Plas maar liefst 254 keer als mede-indiener vermeld."
  },
  {
    "objectID": "posts/moties2023/2023-08-26-kamermotieseda.html#welke-partijen-werken-samen",
    "href": "posts/moties2023/2023-08-26-kamermotieseda.html#welke-partijen-werken-samen",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Welke partijen werken samen?",
    "text": "Welke partijen werken samen?\n\n\n\n\n\n\n\n\nMeestal worden moties ingediend door 1 partij (0 medeindieners dus), maar soms zijn er medeindieners. Er zijn twee moties met 19 medeindieners: Onderzoek minder dierenproeven en Inzien stukken Bijlmerramp\n\n\n\n\n\n\n\n\nHeel duidelijk is te zien dat GroenLinks en PvdA samenwerken. Hierdoor vallen de andere samenwerkingen wat minder op."
  },
  {
    "objectID": "posts/moties2023/2023-08-26-kamermotieseda.html#welke-partijen-lijken-het-meeste-op-elkaar-qua-stemgedrag",
    "href": "posts/moties2023/2023-08-26-kamermotieseda.html#welke-partijen-lijken-het-meeste-op-elkaar-qua-stemgedrag",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Welke partijen lijken het meeste op elkaar qua stemgedrag?",
    "text": "Welke partijen lijken het meeste op elkaar qua stemgedrag?\n\n\n\n\n\n\n\n\nIn bovenstaande grafiek is het stemgedrag van alle partijen platgeslagen op √©√©n as met een zogenaamde Principal Component Analaysis. Deze as verklaart 33% van het stemgedrag en is dus verre van compleet. Of de staven positief of negatief zijn maakt niet uit, het gaat erom dat vergelijkbare partijen bij elkaar in de buurt liggen. Kennelijk liggen Groenlinks en FVD het meest van elkaar verwijderd.\nHieronder visualiseren we het stemgedrag op twee assen. Op deze manier kunnen we bijna 60% van het stemgedrag beschrijven (dus niet 100%!). Als twee partijen vlak bij elkaar liggen wil dus niet zeggen dat ze altijd hetzelfde stemmen. De horizontale as is groter omdat deze meer van het stemgedrag verklaart.\n\n\n\n\n\n\n\n\nEr zijn grofweg 3 clusters te onderscheiden:\n\nDe regeringspartijen bovenaan\nHet linkerdeel van de oppositie linksonder\nHet rechtse gedeelte van de oppositie rechtsonder"
  },
  {
    "objectID": "posts/moties2023/2023-08-26-kamermotieseda.html#welke-partijen-steunen-elkaar",
    "href": "posts/moties2023/2023-08-26-kamermotieseda.html#welke-partijen-steunen-elkaar",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Welke partijen steunen elkaar?",
    "text": "Welke partijen steunen elkaar?\n\n\n\n\n\n\n\n\nEr moet ook gestemd worden natuurlijk! Boven zie je mooi een paar clusters van partijen die elkaar veel steunen in het stemgedrag. Omtzigt en BBB zijn interessant: links steunen wel regelmatig GroenLinks, PvdA en Volt, maar veel minder PvdD en BIJ1. Rechts steunen ze af en toe nog weleens PVV, Groep van Haga en FVD, terwijl deze onder de andere partijen nauwelijks steun krijgen.\nIn een volgend blog cluster ik de moties naar onderwerp. We onderzoeken welke partijen het meest actief & succesvol zijn op bepaalde onderwerpen. To be continued!\n\n\n\n\n\n\nNote\n\n\n\nBroncode is te vinden op GitHub"
  },
  {
    "objectID": "posts/moties/2021-02-20-kamermotieseda.html",
    "href": "posts/moties/2021-02-20-kamermotieseda.html",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "",
    "text": "De verkiezingen komen er weer aan, en de Tweede Kamer heeft een open data portaal. Daar heb ik eens fijn gebruik van gemaakt en alle moties vanaf 2009 gedownload. Het zijn er om precies te zijn 29514 en in dit blog kijk ik of er interessante inzichten uit te halen zijn."
  },
  {
    "objectID": "posts/moties/2021-02-20-kamermotieseda.html#ontwikkeling-van-het-aantal-moties",
    "href": "posts/moties/2021-02-20-kamermotieseda.html#ontwikkeling-van-het-aantal-moties",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Ontwikkeling van het aantal moties",
    "text": "Ontwikkeling van het aantal moties\n\n\n\n\n\n\n\nHet aantal moties stijgt, met name het aantal aangenomen moties. In verkiezingsjaren (2010, 2012 en 2017) ligt het aantal moties duidelijk lager.\n\n\n\n\n\n\n\nMoties die worden aangenomen halen meestal rond de 120 stemmen. Moties die het niet halen blijven meestal rond de 50 stemmen hangen. Eigenlijk zegt zo‚Äôn gemiddelde niet zoveel en kan je beter naar de verdeling van het aantal stemmen voor kijken, dat doen we nu met een histogram per kabinetsperiode.\n\n\n\n\n\n\n\n\n\nIn de histogrammen gaat het vooral om de verdeling van de moties tijdens de kamerperiodes. * Balkenende IV: een piekje van moties die nauwelijks stemmen krijgen (waarschijnlijk protestmoties), een grote piek met moties die rond de 35 stemmen blijven hangen en een piek met unaniem aangenomen moties * Rutte I: relatief veel moties die het nipt wel of juist niet haalden * Rutte II: veel afgewezen moties * Rutte III: hele grote piek in het aantal unaniem aangenomen moties. Dit lijken er ook steeds meer te worden (500 in 2018, 700 in 2019 en 900 in 2020)\n\n\n\n\n\n\n\nMeestal worden moties ingediend door 1 partij, maar soms zijn er medeindieners. Sinds 2008 is er √©√©n special snowflake motie, met maar liefst 16 medeindieners. Kennelijk stond de hele kamer achter een reddingsplan voor VDL Nedcar."
  },
  {
    "objectID": "posts/moties/2021-02-20-kamermotieseda.html#komt-elke-partij-opdagen",
    "href": "posts/moties/2021-02-20-kamermotieseda.html#komt-elke-partij-opdagen",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Komt elke partij opdagen?",
    "text": "Komt elke partij opdagen?"
  },
  {
    "objectID": "posts/moties/2021-02-20-kamermotieseda.html#welke-partij-is-de-tegenpartij",
    "href": "posts/moties/2021-02-20-kamermotieseda.html#welke-partij-is-de-tegenpartij",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Welke partij is de ‚Äòtegenpartij‚Äô?",
    "text": "Welke partij is de ‚Äòtegenpartij‚Äô?\n\n\n\n\n\n\n\nLogischerwijs steunt de oppositie de meeste moties, terwijl de regering vaak tegen stemt. De VVD blokkeert de meeste moties. Tijdens Rutte I en II waren deze verschillen nog groter."
  },
  {
    "objectID": "posts/moties/2021-02-20-kamermotieseda.html#welke-partijen-dienen-het-meeste-moties-in-en-hoe-succesvol-zijn-ze",
    "href": "posts/moties/2021-02-20-kamermotieseda.html#welke-partijen-dienen-het-meeste-moties-in-en-hoe-succesvol-zijn-ze",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Welke partijen dienen het meeste moties in en hoe succesvol zijn ze?",
    "text": "Welke partijen dienen het meeste moties in en hoe succesvol zijn ze?\n\n\n\n\n\n\n\nIn bovenstaande grafiek zijn de partijen op elkaar gestapeld en is te zien dat het aantal succesvolle moties onder Rutte III sterk is gestegen. De stijging komt vooral door VVD, CDA en Groenlinks.\n\n\n\n\n\n\n\nDeze visualisatie geeft weer hoe succesvol partijen zijn geweest tijdens de verschillende kamerperiodes. Je ziet bijvoorbeeld de PVV, PvdD en SP als partijen met veel moties, maar weinig succesvolle. Ook worden de moties van regeringspartijen vaker aangenomen. Dit komt natuurlijk doordat ze met de regeringspartijen een meerderheid hebben in de TK. Laten we nu eens kijken hoe deze grafiek eruit ziet per zetel, om een ‚Äòproductiviteit‚Äô te meten.\n\n\n\n\n\n\n\nOpvallend vind ik het erg lage aantal moties van de VVD per zetel. Het is natuurlijk ook de partij met het hoogste aantal zetels, maar toch. De PvdA is na Rutte II losgegaan, terwijl Groenlinks iets minder indient, maar wel succesvoller is. PvdD dient het meeste moties in per zetel per jaar. Ook SGP en ChistenUnie zijn behoorlijk succesvol per zetel."
  },
  {
    "objectID": "posts/moties/2021-02-20-kamermotieseda.html#wie-zijn-de-motiekanonnen-van-de-tweede-kamer",
    "href": "posts/moties/2021-02-20-kamermotieseda.html#wie-zijn-de-motiekanonnen-van-de-tweede-kamer",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Wie zijn de ‚Äòmotiekanonnen‚Äô van de Tweede Kamer?",
    "text": "Wie zijn de ‚Äòmotiekanonnen‚Äô van de Tweede Kamer?\nWie is nu het meest ‚Äòsuccesvolle‚Äô kamerlid? * De Producent: Lammert van Raan van PvdD dient maar liefst 86 moties in per jaar, hierbij blijft hij Lisa Westerveld van GroenLinks ruim voor (66 per jaar). * De Winnaar: Deze gaat ruimschoots naar Carla Dik-Faber van de ChristenUnie. Zij is met 41 aangenomen moties verreweg het succesvolst. Joba van den Berg-Jansen (CDA) staat op plek twee met 31 successen per jaar, op de voet gevolgd door wederom Lisa Westerveld (30). * De Samenwerker: Kijken we naar de politicus die het meeste moties heeft mede-ingediend staat daar wederom Dik-Faber maar liefst 94 keer als mede-indiener vermeld. In de code heb ik nog volledige top 10 lijstjes per kamerperiode bijgevoegd voor de geinteresseerden."
  },
  {
    "objectID": "posts/moties/2021-02-20-kamermotieseda.html#welke-partijen-werken-samen",
    "href": "posts/moties/2021-02-20-kamermotieseda.html#welke-partijen-werken-samen",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Welke partijen werken samen?",
    "text": "Welke partijen werken samen?\n\n\n\n\n\n\n\nDuidelijk is hier te zien dat de regeringspartijen vaak samen moties indienen. Van de oppostiepartijen zijn de PvdA, GroenLinks en de SP vaak mede indiener van elkaars moties."
  },
  {
    "objectID": "posts/moties/2021-02-20-kamermotieseda.html#welke-partijen-lijken-het-meeste-op-elkaar-qua-stemgedrag",
    "href": "posts/moties/2021-02-20-kamermotieseda.html#welke-partijen-lijken-het-meeste-op-elkaar-qua-stemgedrag",
    "title": "Data-analyse Tweede Kamer moties",
    "section": "Welke partijen lijken het meeste op elkaar qua stemgedrag?",
    "text": "Welke partijen lijken het meeste op elkaar qua stemgedrag?\n\n\n\n\n\n\n\nIn bovenstaande grafiek is het stemgedrag van alle partijen platgeslagen op √©√©n as met een Principal Component Analaysis. Deze as verklaart 40% van het stemgedrag. Of de bar positief of negatief is maakt niet uit, het gaat erom dat vergelijkbare partijen bij elkaar in de buurt liggen. Kennelijk liggen VVD en PvdD het meest van elkaar verwijderd.\nHieronder visualiseren we het stemgedrag op twee assen. Op deze manier kunnen zo‚Äôn 60% van het stemgedrag beschrijven (niet 100%!). Als twee partijen vlak bij elkaar liggen wil dus niet zeggen dat ze altijd hetzelfde stemmen. De horizontale as is groter omdat deze meer van het stemgedrag verklaart.\n\n\n\n\n\n\n\nDe x-as lijkt toepasselijk de politieke links-rechts as te beschrijven. De y-as is iets lastiger te duiden, iets met samenwerken vs alleenstaan? Waarschijnlijk komt dit doordat FvD en PVV vaak moties indienen die zij alleen steunen maar de rest van de partijen niet zoals we hebben gezien.\nEr zijn grofweg 3 clusters te onderscheiden: * de oppositie linksonder * de regeringspartijen rechtsonder * PVV en FvD bovenaan.\nIk heb het ook nog met de afgelopen kabinetten vergeleken en komt erop neer dat de ChristenUnie en D66 vaak iets meer naar het midden zitten. In die zin is een ‚Äòlinkse samenwerking‚Äô van GroenLinks logischer met SP dan met D66. SGP zit vaak vlakbij de regeringspartijen.\nIn een volgend blog (dat ik hopelijk nog voor de verkiezingen publiceer) bekijk ik de inhoud van de moties. Kijken of er trends zijn in onderwerpen en welke partij het meest actief is op bepaalde onderwerpen.\n\n\n\n\n\n\nNote\n\n\n\nIk heb enkele visualisaties in de blog achterwege gelaten om het nog enigzins leesbaar te houden. Op Google Colab is deze beschikbaar. De code staat op GitHub (Python)"
  },
  {
    "objectID": "posts/lss/2025-08-27-leansixsigma.html",
    "href": "posts/lss/2025-08-27-leansixsigma.html",
    "title": "Lean Six Sigma",
    "section": "",
    "text": "Inspired by some recent Lean Six Sigma posts, I thought it‚Äôs about time I wrote a blog post on it. I want to convey what I see as the essentials. If you apply this, I believe you can get a lot of the benefits.\nThere can be a certain elitism around the mysteries of Lean Six Sigma. A lot of tools with strange Japanese names. And those difficult statistics! Many practitioners have gone through training, trying to wrap their head around all of the tools and statistics. But the method is much more important than the tools. Seeing the forest through the trees‚Ä¶\nAt the core it‚Äôs really simple ‚Äî but not simplistic. Many initiatives fail this logic. Below the 5 steps from the Six Sigma DMAIC method and the pitfalls I often see.\nDMAIC 5 Steps (with pitfalls)\n\nDefine: What is the problem\n\n\nWork is done on on a solution for no problem.\nThe problem or the benefits it will bring the organisation are not well defined\nThere is no a clear owner of the problem, not enough people available to work on the problem\n\n\nMeasure: How big is the problem\n\n\nThe magnitude of the problem is not measured\nThe problem is worked on is not very important, taking away valuable resources from ‚Äòreal‚Äô problems.\n\n\nAnalyse: What causes the problem\n\n\nWork starts on symptoms, not the root cause\nWork is done on causes that don‚Äôt really solve the problem\n\n\nImprove: Fix the root cause\n\n\nThe root cause is simply not fixed. Projectmanagement often. Work begins but is never completed since other priorities show up or discussions keep coming up.\n\n\nControl: Don‚Äôt slide back\n\n\nThis is just a matter of priority\n\nAs you can see these 5 steps are nothing fancy. Really applying them with common logic and consistency will get you quite far.\nAnd then there is also Lean. If I really had to simplify it to one sentence: think in process steps, make sure to only do things that add value and try to minimize/automate the rest. And it‚Äôs about people, so also make the work worthwhile and fun. So OK that‚Äôs two sentences.\nWhat about statistics? Statistics are fun, but like I learned from Master Black Belt Marcus Witteman: practical, graphical, analytical. In that order. So first ask the right question, identify the right graphs and then worry about p-values. It depends on the problem whether they are necessary (often not).\nSo it‚Äôs not magic, it‚Äôs mostly logical thinking applied with discipline. While I don‚Äôt do formal LSS projects, I use this conceptual framework very frequently to check if we are doing things right. LSS offers a mindset anyone can use."
  },
  {
    "objectID": "posts/glide/2022-01-03-glide_image_model.html",
    "href": "posts/glide/2022-01-03-glide_image_model.html",
    "title": "Playing around with GLIDE image model",
    "section": "",
    "text": "You probably know that a computer can describe an image. For example an image of a dog playing with your kids may be translated into ‚Äòdog and children in garden‚Äô.\nBut did you know the other way around is now also possible? You come up with a text and the computer renders a new image. Completely new, not like a Google search which searches existing images.\nOpenAI has been one of the premier organisations publishing spectacular results in the past years. They train their models on huge datasets of texts and images. They released a paper on their GLIDE image model, trained on several hundred million images. It outperforms their previous ‚ÄòDALL-E‚Äô model in terms of photorealism.\nThey also open-sourced a slimmed down version of their model. I played around with it by coming up with text prompts and let the model generate 10 images for each promt.\nBelow the results. Zoom in on pc with ctrl+mousewheel or on mobile with your fingers. I repeat the text above the images keep it readable while zoomed in.\n\nWhat do you think? Some things I noticed: * The more complex prompts sometimes are only partially fulfilled. For example: a monkey looking at itself in the mirror often does not render the mirror. * The representation sometimes is off, for example the secondright rubber ducky. * The model can be quite wide in it‚Äôs approach. When you think of a ‚Äòmap of a city‚Äô, you probably have 1 type of map in your head. The model generates all sorts of types of maps, all believable\nI also had a culinary adventure: Tried out ‚Äòspagetthi on a plate‚Äô but got results that didn‚Äôt look like somethink I‚Äôd like to consume‚Ä¶ Turned out I misspelled it (should be spaghetti) and the corrected text looked much better. To finish it off, I tried to make it ‚Äúdelicious‚Äù and worked out pretty nicely, often the spaghetti get‚Äôs some vegetables on top. So next time you order spaghetti in a restaurant, make sure to spell it right!\n\nThe full GLIDE model is larger and also is trained on images of people. See these impressive examples from the paper:\n\nThis clearly is a disruption to the stock photo business and does have a wide variety of use cases.\nAt this point AI can generate believeable news articles including images that are completely false. Still though, many experts feel that we are currently a long way from Artifical General Intelligence and the current deep learning architectures may not get us to AGI.\nTo me, that doesn‚Äôt make these ‚Äònarrow‚Äô intelligence less impressive. Hope you enjoyed it!\n\n\n\n\n\n\nTip\n\n\n\nThere are even more examples in the paper, check it out! And in case you can‚Äôt get enough, I‚Äôve got even more examples"
  },
  {
    "objectID": "posts/energy/2023-05-22-prices.html",
    "href": "posts/energy/2023-05-22-prices.html",
    "title": "Variation in electricity prices",
    "section": "",
    "text": "Electricity prices are not fixed. They depend on the amount of power generation capacity and demand. In the Netherlands we have a hourly price, which is determined one day in advance. Some power suppliers offer so called ‚Äòdynamic‚Äô contracts, where these hourly prices are used for billing, instead of a fixed price. I like it: you become more aware of your consumption, learn something about prices patterns of electricity and save (a little) on costs.\nIn this blog post, I will show you how electricity prices have changed over time and calculate the potential of shifting your demand.\n\nHistorical prices\n\nFrom 2021 onwards things have been ‚Äòinteresting‚Äô! There are huge swings in the prices, both between the days, but also within the days. In 2023 so far prices have dropped.\nThe highest spread was at August 28th 2022, with a minimum price at 15:00 of -37 cents per kiloWatt-hour (kWh). At 20:00 the price was 699 cents/kWh!\n\n\nWhich days are most expensive (or cheap)?\n\n\n\n\n\n\n\nPrices are lowest on Sundays. Apparently a good day to do the laundry!\n\n\nWhich hours are most expensive (or cheap)?\n\n\n\n\n\n\n\n\n\n\n\n\nC:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_13176\\3753049483.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  test = df[df['year']==2022].groupby('month').mean()['price'].reset_index()\n\n\n\n\n\n\n\n\n\nC:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_13176\\302183373.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  test = df[df['year']==2023].groupby('month').mean()['price'].reset_index()\n\n\n\n\n\n\n\nOn average, the prices are highest at 8:00 and 19:00, and lowest at 3:00 and 13:00. I learned this is called a duck curve.\n\n\n\n\n\n\n\nThis graph is another way of looking at it. The line shows that on average the price at 19:00 is 80% of the maximum price that day.\nThe heatmap shows this 80% at 19:00 is a result of it often being the most expensive price of the day (the dark blue square). But not always, otherwise it would be 100%.\n\n\n\n\n\n\n\nIf we compare the normalized prices 2022 with 2017 we see a couple of changes: The lowest prices used to be at night but are now at 13:00. In addition, 19:00 is even more often the highest price of the day.\n\n\nHow much can you save by shifting your electricity demand?\nSome of your electricity consumption is not flexible. Some devices never turn off (e.g.¬†refrigerator). Some consumption is not easy to move in time (e.g.¬†when you cook).\nBut some demand is flexible, for example:\n\nA dish washer (0.5-1 kWh per cycle)\nA washing machine (0.7-1.2 kWh per cycle, add 1-3 kWh with a dryer)\nAn electric car (dependent on battery)\n\nLet‚Äôs say we can shift 1 kWh daily. Let‚Äôs also assume you currently are using that 1 kWh somewhere randomly between 9:00-20:00.\n\n\n\n\n\n\n\nIf you would have shifted this demand optimally to the lowest point in the day you would have saved ~‚Ç¨360 in 2022. You could also do it simpler, by always shifting your 1kWh demand to 13:00. Since 2022 this strategy is bringing in ~60% of the optimal strategy. These savings are highly dependent on the actual prices and how much you can shift from which hour.\n\n\nTakeaways\n\nShift your flexible demand as much as possible to 13:00, preferably in the weekend. Electricity is cheapest and CO2 emissions are much lower due to solar production.\nThis simple rule of thumb is already bringing in ~60% of your savings potential.\nGet a dynamic energy contract to actually save this potential yourself. If you have solar panels it works differently with ‚Äòsalderen‚Äô. Also you do run the risk of paying more when prices increase.\n\n\n\n\n\n\n\nTip\n\n\n\nTwo websites I can recommend if you want to know more are:\n\nCO2 monitor, showing the emissions of our energy usage\nEnergieopwek.nl, showing the sources of our electricity\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nSource electricity data obtained from ENTSO-E\nSource notebook at GitHub\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\n\nPrices can change rapidly, so this historic analysis is not necessarily a good predictor of the future.\nViews on this blog are my personal opinion."
  },
  {
    "objectID": "posts/datascience/2020-10-31-data_science_setup.html",
    "href": "posts/datascience/2020-10-31-data_science_setup.html",
    "title": "Current preferred data science setup",
    "section": "",
    "text": "I‚Äôve spend some time tinkering with getting a preferred data science stack up. In this post I‚Äôm detailing the choices made and could also help you get started on GCP. If you just want to start with programming, go to Google Colab and you‚Äôre set to go.\n\nThe data science setup is now made up of:\n\nAll development in Python (installed via Miniconda), with Pytorch and Fast.ai for deep learning\nA personal computer with Windows 10, VSCode with Jupyter notebooks functionality\nGoogle Cloud Platform with a Docker container running Linux Ubuntu\nGithub for storing the codebase and a github action based blog running fastpages\n\nFor me this works best at the moment. Some remarks on tradeoffs.\n\nPython vs other languages. Python is todays language of choice for data science. It‚Äôs just so simple to express ideas in code. Also there are just so many packages available with useful functionality that the whole world is basically an import statement away. Maybe I‚Äôll learn Julia, Kotlin or Swift once, but for now I‚Äôm set.\nPytorch vs TensorFlow: Pytorch is so much easier compared to Tensorflow. I remember doing an introduction on Tensorflow and I found it difficult to grasp.\nPytorch vs Fast.ai. Fast.ai is kind of the Keras of Pytorch. It has been a blessing and I do highly recommend it. The online course is great. Also you can get a deeplearning model running in no time. But it‚Äôs also an extra layer of abstraction to remember on top of trying to learn Pytorch. So right now I‚Äôm now mostly using with Pytorch and Fast.ai once in a while.\nWindows vs Linux: OK for data science everyone says Linux is the go to, but I‚Äôm just so accustomed to Windows! I can definitely see the advantages of Linux and are slowly gravitating towards using a command line interface more. Windows made a big step with WSL2, so you can now run Linux from within Windows easily, so I did install Ubuntu locally. Maybe in the future I‚Äôll switch fully to Linux, but for now this is working fine.\nVSCode vs Jupyter Notebooks. In my opinion the setup of running notebooks within VSCode combines the advantages of a fully fledged IDE with the agile development that notebooks are known for.\nHaving an own computer vs doing everything in the cloud. Working in the cloud always has a startup of a couple of minutes. My time is limited, so I do prefer to open VSCode and start coding right away. When I need more compute I use the cloud.\nGCP vs other cloud platforms. This decision was taken based on the $300 free credit you get with GCP.\nGithub: Initially I had all the code on my local computer and I used Git for version control. Now that I sometimes iterate between working locally and in the cloud, I store the main branch on Github and push/pull from whichever environment I‚Äôm working on.\nFastpages: First I started on Medium, but fastpages is a live saver for publishing from notebooks. It makes it actually fun to blog, instead of a chore duplicating your work in a blog article\nDocker: For reproducibility, Docker is king. For cloud computing I think it‚Äôs the best way. You just make a Dockerfile and know what you will get. Also it can make the steps to deployment easier.\nApp deployment: Don‚Äôt know what the best is yet. Have tried Render, and could get a webserver it to work with GCP as well. You can even deploy on Binder with a notebook. Guess this one depends on the use case.\n\nThe remainer of the post is dedicated to helping you out with setting up GCP with Docker. Some things you need:\n\nThe CLI command from Windows to get a VM running\nA startup script to make sure the VM runs the container\nA Dockerfile to build a docker image from\n\nLet‚Äôs start with the CLI command\n\ngcloud beta compute instances create gpu `\n--zone=us-central1-c `\n--machine-type=n1-standard-8 `\n--subnet=default `\n--service-account=YOURSERVICEACCOUNT-compute@developer.gserviceaccount.com `\n--image-family=common-cu110 `\n--image-project=deeplearning-platform-release `\n--boot-disk-size=50GB `\n--scopes=https://www.googleapis.com/auth/cloud-platform,https://www.googleapis.com/auth/devstorage.full_control `\n--accelerator=type=nvidia-tesla-k80,count=1 `\n--metadata=install-nvidia-driver=True `\n--maintenance-policy=TERMINATE `\n--metadata-from-file startup-script=startup-gpu.sh `\n--preemptible\n\nYou can create a GCP VM from the command line interface (CLI) or through the browser based console. Play around with the console to get an idea. Then, on the bottom click gcloud command to see the CLI command to copy in your terminal\nThis command uses ` at end of line since it‚Äôs run from Windows Powershell. If you use Linux, use backslash\n\nDon‚Äôt use Container Optimizer OS, as of november 2020 they dont install nvidia container runtime, meaning it‚Äôs difficult to make use of the GPU inside the container. An approach that works is to use a data science image like common-cu110 as I‚Äôve used here.\nThe K80 is the cheapest GPU, good for experimenting.\nAlso, use ‚Äìpreemtible. You‚Äôre VM may be stopped unexpectedly, but it‚Äôs about 66% cheaper!\nNext up is the startup script‚Ä¶\n\n#!/bin/bash\n# first some waiting until gpu drivers are truly installed\nwhile ! [[ -x \"$(command -v nvidia-smi)\" ]];\ndo\n  echo \"sleep to check\"\n  sleep 5s\ndone\necho \"nvidia-smi is installed\"\n\nwhile [[ $(command nvidia-smi| cut -c1-10) == \"NVIDIA-SMI\"* ]];\ndo\n  echo \"$(command nvidia-smi)\"\n  echo \"sleeping to check\"\n  sleep 5s\ndone\necho \"$(command nvidia-smi)\"\necho \"nvidia-smi drivers are up\"\n\n# if you have a persistent disk you can use this to automatically mount it, otherwise remove it\nif [ ! -d \"/mnt/disks/storage\" ] \nthen\n  sudo mkdir -p /mnt/disks/storage\n  sudo mount -o discard,defaults /dev/sdb /mnt/disks/storage\n  sudo chmod a+w /mnt/disks/storage\n  sudo cp /etc/fstab /etc/fstab.backup\n  sudo blkid /dev/sdb\n  echo UUID=`sudo blkid -s UUID -o value /dev/sdb` /mnt/disks/storage ext4 discard,defaults,nofail 0 2 | sudo tee -a /etc/fstab\n  echo \"mounting complete \"\nelse\n  echo \"not first startup\"\nfi\n\n# startup your Docker container, with port 6006 mapped to Docker for Tensorboard\ngcloud auth configure-docker\ndocker run -d -p 0.0.0.0:6006:6006 --gpus all --ipc=\"host\" -v /mnt/disks/storage:/ds gcr.io/delta-deck-285906/dockerfile  \necho 'Docker run with GPUs'\n\nThe first part of the startup script is mainly to wait until the gpu drivers are properly installed. Otherwise, docker run ‚Äìgpus all will throw an error. Additionally, I like to use a persistent disk. To avoid the hassle of having to mount it every time I startup a new VM, this script does the work for you. Finally the most important is the Docker run instruction. It opens your container with GPU support. The first time you start up your VM it will take some minutes, but afterwards it‚Äôs almost immediate.\nAfter this I like to connect to the running container with Vscode Remote-Container Attach to running container command. Checkout the Vscode docs for how to set this up. Basically you need to put the external ip of the VM into your SSH config file and add a line to your settings.json\n\n# settings.json\n\"docker.host\": \"ssh://YOURUSER@xxx.xxx.xxx.xxx\",\n\n\nHost xxx.xxx.xxx.xxx\n  HostName xxx.xxx.xxx.xxx.xxx\n  IdentityFile localpath/to/publicsshkey\n  User YOURUSER\n  StrictHostKeyChecking no\n\nOne final file to share: the Dockerfile which you can use to build your Docker image\n\nFROM nvidia/cuda:10.2-runtime-ubuntu18.04\n\n##Set environment variables\nENV LANG=C.UTF-8 LC_ALL=C.UTF-8\n\nRUN apt-get update --fix-missing && apt-get install -y wget byobu\\\n    curl \\\n    git-core \\\n    python3-virtualenv \\\n    unzip \\\n    && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*\n\nRUN wget --quiet https://repo.anaconda.com/miniconda/Miniconda3-py38_4.8.3-Linux-x86_64.sh -O ~/miniconda.sh && \\\n    /bin/bash ~/miniconda.sh -b -p /opt/conda && \\\n    rm ~/miniconda.sh && \\\n    ln -s /opt/conda/etc/profile.d/conda.sh /etc/profile.d/conda.sh && \\\n    echo \". /opt/conda/etc/profile.d/conda.sh\" &gt;&gt; ~/.bashrc && \\\n    echo \"conda activate base\" &gt;&gt; ~/.bashrc\n    \nENV PATH /opt/conda/bin:$PATH\n\nRUN pip --no-cache-dir install --upgrade \\\n        altair \\\n        ipykernel \\\n        kaggle \\\n        fastbook \\\n        tensorboard \\\n        diskcache \\\n        && \\\n    conda install -c fastai -c pytorch fastai && \\\n    pip uninstall -y pillow && \\\n    pip install pillow-simd --upgrade && \\\n    mkdir -p ds/.kaggle && \\\n    git clone https://github.com/fastai/fastbook.git /ds/fastbook\n\n# Open Ports for Jupyter\n# EXPOSE 7745\n\n#Setup File System\nENV HOME=/ds\nENV SHELL=/bin/bash\nENV KAGGLE_CONFIG_DIR=/ds/.kaggle\nVOLUME /ds\nWORKDIR /ds\n\n# Make sure the container stays open\nCMD tail -f /dev/null\n\nThe Docker tutorial by Hamel Husain has helped me greatly, especially the advice to use someone elses dockerfile and start making it your own by gradually adapting. The above dockerfile is based upon his actually.\nThat‚Äôs it, hope it has helped you!"
  },
  {
    "objectID": "posts/cars/2017-06-29-cars.html",
    "href": "posts/cars/2017-06-29-cars.html",
    "title": "Finding a second hand car bargain",
    "section": "",
    "text": "When doing the Udacity Machine Learning Engineer course some years ago I had to come up with a capstone project. Being in the market for a new car, I decided to see if I could predict the price of a second-hand car. This project followed a typical data science workflow:\n\nComing up with an idea This step if not always mentioned, but it is and extremely important step. If you don‚Äôt come up with an idea you cannot realize it!\nData gathering I choose gaspedaal.nl as site and scraped about 350.000 cars from it. Scraping itself can be legally sketchy, but since this was an academic project and I didn‚Äôt overload the server I figured it would be ok. Also Gaspedaal.nl is itself a site that scrapes several car marketplaces.\nData cleaning & preprocessing This step makes sure the data will be of use for a model. It involves removing certain outliers, processing of categorical variables. We all know the garbage in, garbage out principle.\nModel selection The model should generate predictions, but which algorithm to choose. Trying out helps! Choosing some sensible options and pick the best performing one. When you execute a project in a corporate setting of course other deliberations are important such as maintainability, robustness and speed\nModel optimizing Many models have a set of knobs to turn, but what position to put them in for the best results. Again: trying out helps. I‚Äôm still looking for a nice Design of Experiments package to do this, but in this project I used the RandomGridSearch, which basically tries and sees what works.\nModel interpretation People often complain about machine learning being a black box, but when you‚Äôre not dealing with neural nets that statement is incorrect. Visualisation is the easiest step, but there are also packages that open up the black box, such as the shap package.\n\nThe model worked nicely and I was able to find a reasonably priced Toyota Prius with it. It has two weaknesses though: * The prices on the website are asking prices, not the final selling price. * If the model shows a car is ‚Äòcheap‚Äô, it may be it has other problems (no maintenance? damage?). That‚Äôs why I did test the car at my own garage before making the purchase."
  },
  {
    "objectID": "posts/bgg/2022-01-19-boardgames.html",
    "href": "posts/bgg/2022-01-19-boardgames.html",
    "title": "Diving into BoardGameGeek",
    "section": "",
    "text": "UPDATE: I‚Äôve launched BoardGameFinder where you can find and explore games based on similarity. Give it a try!\n\nDo you like board games? If you do, you may wonder what other great games are out there. I admit that it‚Äôs a bit of a guilty pleasure of mine. Many people turn to BoardGameGeek (BGG). This is a great site with many users rating games. I used the BGG API to gather information about: * 410K users rating 19M games * Information on 22K games, such as game type, complexity, minimum age, game duration etc\nThe key insights from this dataset are: * New games receive higher ratings * More complex games receive higher ratings * Less active users give higher ratings\nIn this post we take a deeper look into these insights and explore alternative ways of ranking the best games.\nLet‚Äôs dive in!\n\nThe users and ratings\n\n\n\n\n\n\n\n\n\nUsers give ratings that are often rounded: they give a 7 instead of a 7.23, that‚Äôs why you see the spikes on the leftmost chart. Around 4 million reviews end up with a 7.\nLooking at the games, we see a nice normal distribution.\n\n\n\n\n\n\n\n\n\n\n19% of users only leave 1 rating. Together they only account for 0.5% of all ratings\n5% of users (20k) rating &gt;200 games. Together they account for 27% of all ratings\n44% of games receive &lt;100 ratings. However, these ratings only account of 6% of all ratings.\n7% of games have &gt;2000 ratings. Together they account for 39% of all ratings.\n\n\n\n\n\n\n\n\nTable¬†1: Most active users\n\n\n\n\n\n¬†\nuser\ncount\naverage\n\n\n\n\n1\noldgoat3769967\n6471\n6.185752\n\n\n2\nwarta\n6289\n7.230800\n\n\n3\nleffe dubbel\n6068\n5.937541\n\n\n4\nTomVasel\n5672\n6.401869\n\n\n5\nDoel\n5131\n7.496200\n\n\n\n\n\n\n\n\n\n\n\n\nTable¬†2: Most rated games\n\n\n\n\n\n¬†\nName\ncount\naverage\n\n\n\n\n1\nPandemic\n108971\n7.594996\n\n\n2\nCarcassonne\n108881\n7.416162\n\n\n3\nCatan\n108195\n7.133179\n\n\n4\n7 Wonders\n90110\n7.733539\n\n\n5\nDominion\n81623\n7.607675\n\n\n\n\n\n\n\n\nCheck out the insane number of ratings by oldgoat. And 3 games so close to each other with &gt;100K ratings!\n\n\nDevelopments over the years\n\n\n\n\n\n\n\n\n\nThere has been incredible growth in the amount of boardgames being released. It does appears to slow down, although many games are for some mysterious reason added a couple of years after they have been released. Therefore the steep drop after 2020 is a bit misleading.\n\n\n\n\n\n\n\n\n\nAre games being rated higher? After 2005 it seems so! Are games nowadays just better or is there a tendency to rate new games higher? Now luckily I‚Äôve composed this dataset already twice in the past, we can make good use of this:\n\n\n\n\n\n\n\n\n\nMy conclusion would be that it‚Äôs a mix of improved quality and hype: * Scores have been climbing since 2005. There is a rough consensus that boardgames have improved in quality. * As you see the 3 snapshots diverge around 2015. This is a ‚Äòhype‚Äô effect, where the early adopters score a new/upcoming games higher. For any year, the blue line (the ratings from the dataset in 2019) scores highest, after the orange (2020) and lowest in the most recent version of the dataset (2022). Games from 2020 where rated with 7.8 in 2020, but two years later that has dropped to 7.2 and now games from 2022 are rated with 7.8! When games are about 5 years old the ‚Äòhype‚Äô effect is more or less gone and games reach a stable score (around 2014 there is no difference anymore).\nEdit: some BGG users are pointing out it may also have to do with users getting more selective in which games they play\n\n\nComplexity of games\n\n\n\n\n\n\n\n\n\nBGG has a weight metric, which means how complex a game is. To get a feel what a number means, here some examples: * Monopoly: 1.3 * Catan: 2.3 * Chess: 3.7\nMost of the games have a fairly low weight.\n\n\n\n\n\n\n\n\n\nThere is a relation between the complexity of the game and the score. More complex games get higher scores, it‚Äôs almost a 1 point difference between a game with weight 1 and 5! Are heavy games really ‚Äòbetter‚Äô than ‚Äòlight‚Äô games?\n\n\nAre active users more critical?\n\n\n\n\n\n\n\n\n\nHere you see the average rating that different user groups are giving. I‚Äôve split the population in 3 parts that all account for 33% of the ratings. The very active group gives lower scores (6.9 avg) compared to the active users (7.2 avg) and the normal users (8.1 avg). The very active users only make up of 6% the population (note it‚Äôs a small area), they do give out 33% of the ratings!\nAre normal users less critical or just reviewing better quality games?\nIt‚Äôs notable that 11% of all users give only 10 ratings, which accounts for 0.5% of all ratings. You can make a case for filtering these ratings out, since they don‚Äôt distinguish games. Although it could also be users only rating their favorites.\nSome of the games are rated by many users that have only rated a single game with a 10. A good example of such a game is Goblin Grapple, but there are around 100 games where this occurs.\nEdit: as pointed out on reddit these single review users could be playtesters or people that just tried that single game.\n\n\nWhat is the best game?\nWhile doing this project so many ideas came to mind on how an alternative ranking could be defined: * Excluding ratings given by inactive users (I took &lt;=10 as threshold) * Excluding games that have received ‚Äòfew‚Äô ratings (I took &lt;= 1000) * Accounting for the complexity bonus, so that lighter games end up higher.\nOther ideas: * Account for the release year. This approach I abandoned, since some new games are truly better. The only thing you want to account for is removing the ‚Äòhype‚Äô effect. I did this by excluding games after 2017 from the analysis. * Including ratings with a comment, since these people are more strongly opinionated. It did not differ much. * Training a model that takes the average user rating into account, to account for people consistently rating high or low.\nLet me show you some of the outcomes\n\n\n\n\n\n\n\n\n\nname\navg_rating\nyearpublished\naverageweight\n\n\n\n\n1\nGloomhaven\n8.64\n2017\n3.87\n\n\n2\nTwilight Imperium: Fourth Edition\n8.59\n2017\n4.26\n\n\n3\nPandemic Legacy: Season 1\n8.56\n2015\n2.83\n\n\n4\nWar of the Ring: Second Edition\n8.45\n2012\n4.17\n\n\n5\nGaia Project\n8.43\n2017\n4.37\n\n\n6\nStar Wars: Rebellion\n8.38\n2016\n3.73\n\n\n7\nTerraforming Mars\n8.36\n2016\n3.24\n\n\n8\nToo Many Bones\n8.36\n2017\n3.84\n\n\n9\nThrough the Ages: A New Story of Civilization\n8.35\n2015\n4.41\n\n\n10\nAeon's End: War Eternal\n8.34\n2017\n2.93\n\n\n\n\n\n\n\nThis corresponds more or less to the top games listed on BGG. Note from ‚Äòaverageweight‚Äô that these are all pretty heavy games. Also 2017 appears 5 times.\nBut I don‚Äôt have time to play games that are very complex and take many hours! So let‚Äôs account for the complexity, such that great lighter games will pop up more. I trained a tree based model with a r2 of 0.3. It‚Äôs only 0.3, but that does mean that 30% of the variation in the rating is explained by the complexity!\n\n\nBest games with complexity taken into account\nI trained a model that tries to predict the rating of a game based on it‚Äôs complexity. What the model cannot explain by complexity (so-called residuals) is more or less the quality of the game without the complexity bias. I‚Äôve taken 1000 reviews as a minimum for the game to be included. That is pretty harsh (only leaves ~15% of the games), but I wanted to be able to recognize some games. This results in the following top 10:\n\n\n\n\n\n\n\n\n\nname\nresidual\naverage\nyearpublished\naverageweight\n\n\n\n\n1\nCrokinole\n1.75\n7.95\n1876\n1.25\n\n\n2\nMonikers\n1.61\n7.80\n2015\n1.06\n\n\n3\nTelestrations: 12 Player Party Pack\n1.56\n7.75\n2011\n1.07\n\n\n4\nTime's Up! Title Recall!\n1.51\n7.71\n2008\n1.19\n\n\n5\nKLASK\n1.45\n7.64\n2014\n1.08\n\n\n6\nPandemic Legacy: Season 1\n1.42\n8.59\n2015\n2.83\n\n\n7\nEscape the Dark Castle\n1.32\n7.51\n2017\n1.23\n\n\n8\nTime's Up! Edici√≥n Amarilla\n1.30\n7.49\n2008\n1.11\n\n\n9\nEat Poop You Cat\n1.26\n7.45\n0\n1.11\n\n\n10\nMythic Battles: Pantheon\n1.26\n8.43\n2017\n3.03\n\n\n\n\n\n\n\nThis list is ordered by residual, the part that the model could not explain. There are a lot of dexterity and party games in the top, which are of course light games. Pandemic Legacy scores high even while being fairly complex. I was a bit shaken by Eat Poop You Cat, but it seems a nice game you can play with pen and paper. If we filter out the easiest games we get the following list:\n\n\n\n\n\n\n\n\n\nname\nresidual\naverage\nyearpublished\naverageweight\n\n\n\n\n1\nPandemic Legacy: Season 1\n1.42\n8.59\n2015\n2.83\n\n\n2\nMythic Battles: Pantheon\n1.26\n8.43\n2017\n3.03\n\n\n3\nGloomhaven\n1.24\n8.74\n2017\n3.87\n\n\n4\nStar Realms: Colony Wars\n1.22\n7.85\n2015\n1.90\n\n\n5\nAzul\n1.21\n7.80\n2017\n1.76\n\n\n6\nAeon's End: War Eternal\n1.21\n8.38\n2017\n2.93\n\n\n7\n7 Wonders Duel\n1.19\n8.11\n2015\n2.22\n\n\n8\nTwilight Imperium: Fourth Edition\n1.18\n8.68\n2017\n4.26\n\n\n9\nPatchwork\n1.14\n7.64\n2014\n1.62\n\n\n10\nKingdom Death: Monster\n1.11\n8.61\n2015\n4.26\n\n\n\n\n\n\n\nWe do see some heavy games popping back, but there are lighter games as well. I know Pandemic, Azul, 7 Wonders Duel and Patchwork to be great games!\n\n\nWrapping things up with a complete model\nFinally I‚Äôve also trained a model on multiple variables, e.g.¬†the type of game and the year of publication. This model is able to account for about 50% of the variation between average game scores. I think this is a pretty good result. Below you see the impact of the most important variables.\n\n\n\n\n\n\n\n\n\nAs expected the weight/complexity and year of publication have most impact on the rating of a game. Together they roughly impact the score by 0.5 for each game. In addition certain categories also have a small impact on the score. In more detail:\n\n\n\n\n\n\n\n\n\nThis is what people talk about with ‚Äòexplainable AI‚Äô. All the dots represent games, and if they are on the right side it means the impact on the model was positive (a higher rating). The color is about the feature value, where blue means low and red high.\nWhat works best is saying it out loud: ‚Äòif averageweight is high (red), then the impact is positive and the game will receive higher ratings. For ‚ÄôAdminBetterDescriptionNeeded‚Äô that means that if the game description is lacking, the game will receive lower ratings.\nSo if you want to receive high ratings with your game, just make sure to make it complex, two players simulated wargame that can be played solitaire with miniatures and online as well. You already get the hype effect for free üòã\nWe can also inspect how to model came to it‚Äôs prediction for a single game. Below I took Chess as an example:\n\n\n\n\n\n\n\n\n\nThe average game receives a 6.8 (see the bottom value), then there are all kind of effects going on, with the red bars pushing the prediction higher, the blue ones lower. Chess is quite complex which pushes the prediction up, but it‚Äôs also old. Apparently the model also doesn‚Äôt like you need to be 6 to play it. All these effects together make the model arrive at a prediction of 7.1.\nSummarizing, we have found that there are multiple features that influence the rating of a game. Also we have explored alternatives of ranking the best games. Finally we put everything together with an explainable machine learning model. Hope you enjoyed this dive into the data behind board games!\nThere are also interesting threads on Reddit and BGG discussing this analysis.\n\n\n\n\n\n\nTip\n\n\n\nSome technical info: I‚Äôve used standard Python data science packages such as Pandas and Matplotlib, SQLite for database, trained models with LightGBM and the interpretation with SHAP. For the blogging in a notebook I use Fastpages. All awesome!\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe data is of course owned by BoardGameGeek. If you want to play with the data, I‚Äôve made it into a Kaggle Dataset."
  },
  {
    "objectID": "posts/aoc/2024-12-25-analysis_aoc_stats.html",
    "href": "posts/aoc/2024-12-25-analysis_aoc_stats.html",
    "title": "Advent of Code analysis through the years",
    "section": "",
    "text": "Update Dec 25 2024 with 2024 scores. Hade a great time again, thanks Eric and Reddit!\nSince 2018 I‚Äôm participating in üéÖAdvent of CodeüéÖ and enjoying it a great deal. AoC has been running since 2015, so a sizable amount of data has been generated. Let‚Äôs see what we can learn, starting with the amount of stars awarded."
  },
  {
    "objectID": "posts/aoc/2024-12-25-analysis_aoc_stats.html#section",
    "href": "posts/aoc/2024-12-25-analysis_aoc_stats.html#section",
    "title": "Advent of Code analysis through the years",
    "section": "",
    "text": "In total there have now been more than 23M stars awarded (+5M compared to last year)! And 2024 is just barely finished, many people will earn stars in the days to come.\n\n\n\n\n\n\n\n\nOriginal creator of these plots is Maurits vd Schee.\n2024 most difficult puzzles was Keypad Conundrum. Took me 7 hours.\nLow completion times can be a result of two factors:\n\nThe puzzles were easier\nThe participants where better / more competitive\n\nOne way of investigating the difficulty of a year is by analyzing the completion rate: how many people got all the stars compared to the people that got only 1 star of day 25. These people did make it to day 25, thus put a considerable amount of effort in, but couldn‚Äôt finish all puzzles.\n\n\n\n\n\n\n\n\nIn the above chart, each rectangle symbolizes the people that solved all puzzles during the year. The height shows the completion rate.\nThe completion rate was very high in 2016 and 2017 and has dropped in recent years, corresponding with more participants each year. I found it interesting 2024 has a high completion rate.\nFor 2024 the verdict is still out, right now day 25 has just opened up, so relatively more hardcore participants have finished it, leading to a high completion rate.\n\n\n\n\n\n\n\n\nAgain note that 2024 is very fresh still.\nWe mostly see that the amount of people that got points on the leaderboard is slowly increasing. Probably this is an indication of more competion.\nAnother indicator can be the time it took to solve a puzzle.\n\n\n\n\n\n\n\n\nThe fastest completion times add up to &lt; 2 hours, which is amazing. Since nobody ever finished #1 at all puzzles, this is a theoretical minimum.\nThe completion times of #100 add up to a more ‚Äòhuman‚Äô amount. These times are still way below the amount of time a ‚Äònormal‚Äô participant spends on AoC. For example I consider myself an enthusiast, but my completion times are normally about 2-3x the #100.\nOverall, 2024 was very fast.\n\n\n\n\n\n\n\n\n2023 will move more to the right given time. I‚Äôm not sure anymore if this graph is indicative of anything.\n\nGetting leaderboard points is special. There are people who do it consistently. Let‚Äôs give the top 30 some extra recognitionüéà\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll the people on this top 30 list are amazing, but some awards to hand out:\n\nüèÜRobert Xiao managed to get the most amount of points and overall most leaderboard placements\nüèÜbetaveros got on average most points & leaderboard entries (ignoring anonymous user here). betaveros also managed to get 50 entries is 2018, which was a one-time event\nüèÜglguy for getting the highest score while getting points in all 10 seasons\n\n\nDoing AoC once and get LB points is nice, but it‚Äôs even nicer to do it twice, thrice, etc.\n\n\n\n\n\n\n\n\nMost of the people that get points manage to do it only once. The y-axis is logaritmic. Who are having so much grit to get points all 10 seasons?\n\n\n\n\n\n\n\n\n\nuser\namount_seasons\ntotal_points\ntotal_lb_placements\n\n\n\n\n11\nglguy\n10\n12758\n204\n\n\n15\netotheipi1\n10\n11146\n207\n\n\n21\nmsullivan\n10\n10124\n177\n\n\n22\nKevin Yap\n10\n9400\n169\n\n\n38\n(anonymous user #60233)\n10\n7631\n154\n\n\n\n\n\n\n\nWell done!\n\n\n\n\n\n\n\n\n2024 was touch for our legends, I think this is due to LLM competition. Did ananymous user #60233 embrace LLMs ;-)?\nAll in all an amazing achievement! All in all I think there is a strong case for AoC being more competitive after 2019.\nLet‚Äôs finally turn to which puzzles were easiest or hardest.\n\n\n\n\n\n\n\n\n\npuzzle\nuser\ntime (seconds)\n\n\n\n\n0\n2024-1-1\nqianxyz\n4\n\n\n1\n2024-19-1\nRomain Bourjot\n6\n\n\n2\n2024-1-2\nqianxyz\n9\n\n\n3\n2024-11-1\nJohn Cornwell\n9\n\n\n4\n2024-24-1\nRangerMcSexy\n9\n\n\n\n\n\n\n\nLLMs completely destroyed this list, all fastest solves are now in 2024\n\n\n\n\n\n\n\n\n\npuzzle\nlb full (seconds)\n\n\n\n\n0\n2021-1-1\n65\n\n\n1\n2022-1-1\n76\n\n\n2\n2019-1-1\n84\n\n\n3\n2024-1-1\n84\n\n\n4\n2024-3-1\n84\n\n\n\n\n\n\n\nThis list however is mostly unchanged. The leaderboard capped (the #100 completed the puzzle) after barely a minute in 2021 for the first star!\n\n\n\n\n\n\n\n\n\npuzzle\nuser\ntime (minutes)\ntitle\n\n\n\n\n499\n2018-15-2\nSimon Parent\n36\nBeverage Bandits\n\n\n498\n2018-17-2\nRaven Black\n33\nReservoir Research\n\n\n495\n2018-24-2\nSimon Parent\n28\nImmune System Simulator 20XX\n\n\n494\n2022-22-2\nmrphlip\n25\nMonkey Map\n\n\n493\n2020-20-2\nxiaowuc1\n25\nJurassic Jigsaw\n\n\n492\n2022-19-2\nlukechampine\n24\nNot Enough Minerals\n\n\n490\n2021-23-2\ngoffrie\n23\nAmphipod\n\n\n489\n2024-21-2\ndan-simon\n23\nKeypad Conundrum\n\n\n488\n2019-18-2\nglguy\n22\nMany-Worlds Interpretation\n\n\n487\n2015-22-2\nPaul Hankin\n21\nWizard Simulator 20XX\n\n\n\n\n\n\n\nThe longest 3 solve times were all in 2018! Shoutout to Simon Parent for solving 2 out of the top 3. This list mostly has puzzles that just take a long time to code, with Beverage Bandits as perfect example.\nFor 2024 Keypad Conundrum landed at #8\n\n\n\n\n\n\n\n\n\npuzzle\nlb full (minutes)\ntitle\n\n\n\n\n499\n2015-19-2\n232\nMedicine for Rudolph\n\n\n498\n2015-1-2\n186\nNot Quite Lisp\n\n\n497\n2015-22-2\n183\nWizard Simulator 20XX\n\n\n496\n2016-11-2\n164\nRadioisotope Thermoelectric Generators\n\n\n493\n2018-15-2\n143\nBeverage Bandits\n\n\n492\n2019-22-2\n123\nSlam Shuffle\n\n\n490\n2019-18-2\n117\nMany-Worlds Interpretation\n\n\n488\n2018-23-2\n100\nExperimental Emergency Teleportation\n\n\n487\n2016-22-2\n88\nGrid Computing\n\n\n486\n2018-24-2\n87\nImmune System Simulator 20XX\n\n\n\n\n\n\n\nIf we look at when the leaderboard capped some different puzzles show up. I feel that this list has some more algoritmic challenges (Slam Shuffle for example, but Medicine for Rudolph as well).\n2024 does not show up in the top 10!\nOverall, I feel 2018 is a strong contender for the most difficult year, although with increased competitiveness it‚Äôs getting more difficult to compare it to the recent years.\nHope you enjoyed this analysis and see you back next year! üéÑ‚≠êüéÖ"
  },
  {
    "objectID": "posts/aoc/2021-07-10-aoc.html",
    "href": "posts/aoc/2021-07-10-aoc.html",
    "title": "Advent of Code",
    "section": "",
    "text": "aoc\n\n\nRemember these üéÖAdvent CalendersüéÖ where you open a door each day to find a piece of candy? Advent of Code is like that, but with coding puzzles: from 1st to 25th of December, every day a puzzle unlocks at midnight. Each puzzle has two parts where you can earn a star, so you can earn 2 stars per day, adding up to a total of 50. Since 2015 every year the amount of particpants grows, in 2020 over 150.000 people around the world have participated. You can solve the puzzles any way you like. I‚Äôve always used Python, but anything goes, even Excel (if you are brave).\nI was introduced to AoC in 2018. It was a real challengeü§Ø to solve all the puzzles. In 2020 I tried to compete for the leaderboard, which meant getting up at 5:50AM 25 times in a row, which was an experience in itself. Never did I get a spot in the top 100, but I am proud to be part of the ~700 people who finished all the puzzles from 2015 onwards.\nFor old times sake, I‚Äôve listed my personal Top 9 most memorable puzzles of all time (2015-2020):\n\n9) 2019 Day 23: Category Six\nA nice puzzle where you had to simulate computersüíª receiving and sending packets over a network to eachother. Memorable because I later could use it to practice using Pythonüêç Async.\n\n\n8) 2018 Day 23: Experimental Emergency Teleportation\nGiven a 3D room with many bots that can reach up to a certain distance, what‚Äôs the spot where you can reach most bots? Seems simple, but the room is HUGE! This makes solving the puzzle a nice challenge.\n\n\n7) 2019 Day 13: Care Package\n2019 is a special year for AoC, since you eventually code your own working ‚ÄòIntComputer‚Äô. During day 13, we used this computer to play arkanoid. Later on there were more puzzles where the IntComputer was used.\n\n\n6) 2020 Day 21: Allergen Assessment\nFor many people probably not very memorable, but this got me the 189th spot on the leaderboardüíØ, where I normally hovered around 1600. Usage of sets in Python just came together for me in this one.\n\n\n5) 2019 Day 18: Many-Worlds Interpretation\nMemorable because it was very difficult to solve with code and did it eventually on paper! You‚Äôre in a maze and need collect keysüóù. The keys correspond to doors that open when you find the key. The mechanism of unlocking doors makes the amount of possible states explode.\n\n\n4) 2018 Day 17: Reservoir Research\nAnother one from my first year of participation. You have to simulate waterüåä falling down into buckets. Just a great puzzle to toy around with. All AoC puzzles have some kind of story to them. I found this one to be especially memorable.\n\n\n3) 2016 Day 11: Radioisotope Thermoelectric Generators\nRemember that puzzle of the wolfüê∫, chickenüêî and farmerüë®‚Äçüåæ that have a boat to cross the river? That‚Äôs the one, but now with 5 animals and 3 rivers. I played with lego blocks trying to find the best solution. Didn‚Äôt work, got confused and in the end had to make it into a BFS, which is an algorithm that comes around frequently in AoC.\n\n\n2) 2018 Day 10: The Stars Align\nA puzzle where you are presented with a set of starsüåü that are moving towards eachother. Again a simulation where at a certain point of time the stars align into a code. Animating the stars and having to zoom in into that tiny spot where they formed the code was lots of fun.\n\n\n1) 2019 Day 22: Slam Shuffle\nAnd the number one, the only puzzle in 2019 I didn‚Äôt solve in the same day. Take a deck of cardsüóÉ, apply some operations on it and identify the card in postion 2020. Easy enough right? Yes, untill for part 2 that deck consists of 119315717514047 cards and you have to apply the operations 101741582076661 times! Good luck brute forcing that. It took me around 20 hours to solve the puzzle and was so close to giving up. Such a great feeling when it finally came together. Wrote a small post on reddit on it.\nI‚Äôve uploaded my solutions to GitHub. People post their solutions on the AoC subreddit, which is a great way to learn from the best.\nNeedless to say I highly recommend AoC! See you all December 1stüéÑ!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My most recent blogs",
    "section": "",
    "text": "Lean Six Sigma\n\n\nit‚Äôs not magic, it‚Äôs logical thinking\n\n\n\nAug 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRowing\n\n\n1 million meters in 2024\n\n\n\nDec 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvent of Code analysis through the years\n\n\nWhat can we learn from the stats?\n\n\n\nDec 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTekst analyse van Tweede Kamer moties\n\n\nWie zet wat op de agenda?\n\n\n\nSep 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData-analyse Tweede Kamer moties\n\n\nStemgedrag politieke partijen in de Tweede Kamer\n\n\n\nAug 26, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariation in electricity prices\n\n\nWhat is happening and can you profit?\n\n\n\nMay 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiving into BoardGameGeek\n\n\nKey insights on board game ratings\n\n\n\nJan 19, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlaying around with GLIDE image model\n\n\nOpenAI tackles text to image\n\n\n\nJan 3, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvent of Code\n\n\nSolving puzzles with code\n\n\n\nJul 10, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTurnonderzoek op het journaal\n\n\nTweederde van alle turners heeft te maken met grensoverschrijdend gedrag?\n\n\n\nApr 29, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTekst analyse van Tweede Kamer moties\n\n\nWie zet wat op de agenda?\n\n\n\nMar 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData-analyse Tweede Kamer moties\n\n\nGraven in moties vanaf 2009 [2021]\n\n\n\nFeb 20, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFace2Age\n\n\nPredicting someone‚Äôs age from their face\n\n\n\nNov 24, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCurrent preferred data science setup\n\n\nAnd some tips on getting it to work on Google Cloud Platform\n\n\n\nOct 31, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRed-Black trees\n\n\nA love-hate affair with a data structure\n\n\n\nSep 12, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting the value of a house\n\n\nTop 3% in a data science competition\n\n\n\nJul 26, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring flight patterns above The Netherlands\n\n\nVisualizations of 3.5 million datapoints\n\n\n\nApr 22, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOntwikkeling positieve COVID19 testuitslagen\n\n\nRIVM data door de tijd\n\n\n\nMar 23, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring 13M board game reviews\n\n\nMaking a recommender system for boardgames\n\n\n\nMay 28, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWie is de Mol\n\n\n18 seizoenen van WIDM onder het vergrootglas\n\n\n\nJan 12, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuilding a Crypto Trading Bot\n\n\nA short story about motivation\n\n\n\nMar 2, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinding a second hand car bargain\n\n\nA typical data-science workflow made easy\n\n\n\nJun 29, 2017\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to my blog. Here I share some of my personal data science initiatives."
  },
  {
    "objectID": "posts/age/2020-11-24-face2age.html",
    "href": "posts/age/2020-11-24-face2age.html",
    "title": "Face2Age",
    "section": "",
    "text": "This blog is about predicting someone‚Äôs age by their face. I‚Äôve also made an webpage where you can try to beat the computer.\nDeep learning has seen incredible results the last couple of year. As long as you have a large enough dataset, it you can transform any input to any output. A couple of examples:\n\nImage classification, where you map an image to a label (input an image of a frog, computer outputs ‚Äòfrog‚Äô)\nSentence generation (if I start a sentence with ‚ÄòToday, the weather is‚Äô, computer outputs ‚Äògreat, let‚Äôs take a walk‚Äô.\nRecommender system (which is the next video that will be most likely to keep the user watching) As an aside, deep learning is not without it‚Äôs ethical problems, for example these social media recommender systems have a tendency to radicalize people, since that maximizes their ‚Äòengagement‚Äô to the platform.\n\nIn this project, I‚Äôve taken on a image regression problem. It‚Äôs a nice problem, because the answer is not always obvious: some people look older or younger than they really are. By showing the computer model examples and giving feedback how wrong it is on its prediction, the model is improving. We don‚Äôt have to explain anything about how an old or young person looks like. Can you imagine how difficult it would be to program how to recognize wrinkles? This is essentially the wonder of neural networks.\nWhen training a model, an important part is the performance metric. For this task of guessing someone‚Äôs age, I‚Äôve chosen Mean Absolute Error, basically how many years you‚Äôve guessed wrong. A prediction of 12 on an actual age of 10 means the MAE is 2, just as a prediction of 8 also has an MAE of 2.\nThe dataset contains about 10.000 images, I‚Äôve trained the model on 70% of the dataset. That leaves about 3k images which the model has not seen. We use this to test it‚Äôs performance. In theory, this performance will generalize to other unseen images. In practice that remains to be seen, since real life images can be much messier, e.g.¬†in quality, zoom level and background.\nBelow you can see it getting better over time. The horizontal axis displays how many times we feed the training set to the model. The left graph shows performance on the training set, the right graph on the test set. Initially, it‚Äôs off by about 11 years, and slowly converging to a MAE of 2 years. But taking the performance on the training dataset is cheating, we are interested in it‚Äôs performance on unseen images! The performance there converges to around 4.2.\n\nLet‚Äôs check out predictions on some random images in the test set. In the title the actual age and the predicted age by the model.\n\n\n\n\n\n\n\n\n\nThat looks pretty good! To take a more general approach, let‚Äôs plot the all the images from the test set in a graph.\n\n\n\n\n\n\n\n\n\nThere are definitely some errors, but overall it seems reasonable. It‚Äôs also interesting to plot the faces where the error was largest.\n\n\n\n\n\n\n\n\n\nIn most of the cases the model was simply off, but there are also faces which look much older or younger, or very blurry ones. Which highlights the importance of understanding the dataset and potentially removing outliers from it.\nAnother approach is to visualize the average error by age.\n\n\n\n\n\n\n\n\n\nThe error gets larger as someone gets older, which makes perfect sense: when you see a baby you are not going to guess wrong by more then 5 years, but for someone age 50 that is more difficult.\nYou could argue for a slight improvement in the predictions with ages &gt; 60, but it could also be an anomaly. There are few really old faces in the dataset, which could be of influence. There are also 300 images of babies age 0 in the dataset, which I removed from the second chart to have a better visualisation.\nI‚Äôve build a webpage where you can try out if you can beat the computer, or even upload a selfie for fun to see how old the computer thinks you are. Please take the results with a grain of salt. I‚Äôve taken some selfies and the computer estimated me around 27 to 42, which is ballpark accurate. However, a condolence card of my grandmother age 92 was classified as 62, and although she did look young, 62 was an underestimation.\nI‚Äôve had much fun with this project. I hope you like it as well and will try out the application. No guarantees it will be online indefinitely by the way.\n\n\n\n\n\n\nNote\n\n\n\nTechnical details on how it was build: Pytorch, Pretrained resnet-18 model. Application runs on Google Cloud Platform, with a Nginx and Gunicorn running in Docker container. Python backend in Fastapi. Code available on Github, dataset on Kaggle"
  },
  {
    "objectID": "posts/bgg/2019-05-28-boardgames.html",
    "href": "posts/bgg/2019-05-28-boardgames.html",
    "title": "Exploring 13M board game reviews",
    "section": "",
    "text": "aoc\n\n\nI like playing games, whether it‚Äôs on a computer on as a board game. That‚Äôs why the site boardgamegeek.com is a great resource for inspiration about great games. It has extensive information about games and what people think of them, for example with how many players it‚Äôs best to play and from what age children are ready for it. They also provide an API to interact with the site. I used this to download all the scores that users have given to games.\nUsing these scores it‚Äôs possible to let the computer identify certain latent factors behind games and users. This technique is called collaborative filtering, and it‚Äôs the same as Netflix uses to recommend what to watch next. Or amazon.com to advise on your next purchase.\nIn the end what I did was: * Make it into a Kaggle dataset * Did some exploratory data analysis * Got collaborative filtering working * Made it into a webapp, currently offline where people can search for a game and the app will display the games the user probably likes"
  },
  {
    "objectID": "posts/btc/2018-03-02-cryptobot.html",
    "href": "posts/btc/2018-03-02-cryptobot.html",
    "title": "Building a Crypto Trading Bot",
    "section": "",
    "text": "What drives you when working on a project? For me motivation is made up of several components:\n\nCuriosity: discover new insights about an interesting topic\nReaching a goal: have a sense of progressing to a goal by solving small obstacles\nLearning: grow a skillset and be able to take on larger goals\nChallenge & Mastery: overcoming the nagging feeling if I‚Äôll be also to tackle the project\n\nWhen I had an idea during the rise of bitcoin these elements where definitely there. But there was another big motivator‚Ä¶\nI had made some money with the rise of bitcoin by buying it early and holding on to it. But what would be even better: a constant risk-free return without having to put much effort in. And that was exactly the idea that came to mind. Simple arbitrage: you open an account on multiple crypto exchanges and monitor the prices for different coins. When the prices are drifting apart you take up two positions: buying a coin at exchange A for a low price, and at the same time selling a coin short at exchange B for a high price. Then transferring the coin you‚Äôve bought at exchange A to exchange B to neutralize the position and voila: profit. If I could have a program running on the background this would make me rich! It required a couple of functionalities to program: monitoring the prices though an API, taking up positions, neutralizing these positions and making sure to have enough crypto funds on the buying exchange. The spreads between the exchanged need to outweigh the transaction and transfer costs in order to be profitable.\nI experienced how this sense of building a golden goose boosted my motivation to new highs. Sometimes I focus a lot on projects to make progress, but this was really next level üòä. After many hours of coding and learning to interact with crypto API‚Äôs, I got everything to work automatically. But alas, the opportunities for risk-free arbitrage became very limited, as a result of the markets maturing. The spreads started to get smaller and smaller making my bot not profitable anymore.\nGreed is at the core of many things wrong in this world, but in this case it provided me a very fun and valuable learning experience."
  },
  {
    "objectID": "posts/covid/2020-03-23-analyse.html",
    "href": "posts/covid/2020-03-23-analyse.html",
    "title": "Ontwikkeling positieve COVID19 testuitslagen",
    "section": "",
    "text": "Update 31 maart: Het RIVM is overgegaan op een ander type data, namelijk het aantal ziekenhuisopnames per gemeente, alleen zonder historie te publiceren. Hiermee komt er een einde aan deze visualisatie. Misschien ga ik de ziekenhuisopnames nog een keer visualiseren.\nUpdate 18 april: uiteindelijk is de beste informatie de oversterfte per week. Deze is te vinden op de site van het CBS\nDagelijks publiceert het RIVM de inmiddels welbekende testkaart met daarop het aantal mensen dat per 100.000 inwoners in de gemeente positief is getest op Covid-19. Het leek me interessant om het verloop per gemeente te visualiseren.\nHieronder zie je drie grafieken: - Aantal: Totaal aantal positieve testcases (cumulatief) - Relatief: Totaal aantal positieve testcases per 100.000 inwoners - Groei: Toename van het aantal gevallen ten opzichte van 4 dagen geleden. Factor 0 betekent geen extra gevallen, factor 1 betekent een verdubbeling en factor 2 betekent dat er 2x zoveel cases bij zijn gekomen als dat er 4 dagen geleden waren (een verdrievoudiging van het totaal aantal gevallen).\n\n\n\n\n\n\n\nJe kan met de slider het verloop van de epidemie volgen. Zoom in als je hem moeilijk te pakken krijgt. Dag 0 is 3 maart, dit was de eerste dag waarvan ik data kon terug vinden op de site van het RIVM. De laatste dag is 30 maart.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTenslotte nog een mogelijkheid om het verloop in een specifieke gemeente te bekijken\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nOmdat in Nederland lang niet alle gevallen worden getest ligt het werkelijke aantal cases waarschijnlijk veel hoger. Weinig cases in jouw gemeente wil niet zeggen dat er niet meer gevallen zijn! Ook zal bijvoorbeeld een ziekenhuis in de gemeente de aantallen beinvloeden vanwege relatief vaker geteste zorgmedewerkers. Pas als er in Nederland veel meer gaat wordt getest kan je er echt conclusies aan verbinden. Landelijk zeggen IC opnames momenteel meer.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nJe ziet dat sommige lijntjes heel erg stijl omhoog gaan, dat moeten we proberen te verminderen. Houdt je dus aan de maatregelen en adviezen.\n\n\n\n\n\n\n\n\nNote\n\n\n\nIk ben geen specialist en heb deze data van de RIVM site gedownload. Er kunnen dus ook geen rechten aan worden ontleend. De totalen zullen niet helemaal optellen tot de nationele aantallen omdat er ook gevallen zijn waarvan de woonplaats niet bekend is ten tijde van publicatie. Heb je tips laat maar weten!\n\n\n\n\n\n\n\n\nTip\n\n\n\nBedankt ontwikkelaars van Fastpages (heel handige manier om Jupyter notebooks te bloggen) en Altair (voor de visualisaties). Super om dit eens te proberen."
  },
  {
    "objectID": "posts/flight/2020-04-22-flights_above_nl.html",
    "href": "posts/flight/2020-04-22-flights_above_nl.html",
    "title": "Exploring flight patterns above The Netherlands",
    "section": "",
    "text": "Some years ago I woke up early because of a loud aircraft flying over. Couldn‚Äôt get back to sleep and decided to use these precious early hours to visualize the air traffic around Hilversum.\nEvery aircraft is equipped with a device called a transponder that transmits flight data about the flight into the air. Organizations like OpenSky aggregate these data and make them available. Below a screenshot of the result, you can see the tracks and some information about the flight is displayed.\n\nBut when revisiting this initial project, I felt there were more opportunities. I obtained air traffic above the Netherlands from February to April (monday‚Äôs only), resulting in 11 full days of traffic.\n\n\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs see if there are more interesting patterns and visualisations. First we split the traffic by altitude.\n\n\n\n\n\n\n\n\n\n\nRed: The lowest flying traffic. Airfields such as Eelde, Eindhoven, Dusseldorf and Brussels are visible.\nBlue: All the complex movements of traffic in and out of Amsterdam. These are standard routes being flown to keep the traffic manageable, so called STARs and SIDs.\nGreen: The highest flying aircraft are passing over in mostly straight tracks.\n\nThere are more properties in the data, such as altitude, vertical speed and velocity.\n\n\n\n\n\n\n\n\n\n\nLeft: all the arriving flights are red and departures are blue.\nMiddle: This disco shows aircraft climbing or descending. The colormap is increasing with 1000m per color, starting from red for 0-1000m. Compare it with the left graph: departing flights are quickly climbing to purple, whereas arrivals are flying lower longer. The green to yellow transitions indicate the points where arrival flights are converging for their approach.\nRight: the average speed of the aircraft. Also here you see arrival routes are darker (slower) than departures.\n\nAnd because COVID-19 is here, let‚Äôs plot the data of the past weeks.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÄòNormally‚Äô there are 2700 flights above the Netherlands (including some North Sea) with a total airtime of 840 hours per day. That is the equivalent of about 35 aircraft flying continuously. The graph shows the dramatic slowdown to about 1/8 of the original volume.\nThe firelike image on the left side is slowly turning into a collection of night flies: the slowdown of traffic can be easily seen. This has been analyzed more extensively here.\nI also went through callsigns that occur most often. Grouping different types of traffic results in some interesting patterns. A small quiz: which pattern belongs to: - The coastguard - Aerial photography - Military flights - Emergency care flights (trauma) - Police helicopters - Commercial helicopter flights\nAnswers on the bottom of the post.\n\n\n\n\n\n\n\n\n\nLet‚Äôs end with some visualisations with a certain shade of blue. What type of flights do they represent?\n\n\n\n\n\n\n\n\n\nThat‚Äôs it, I had fun visualizing all of this, hope you enjoyed reading it!\nAnswers to the above: - A = Police helicopters. Lots of hovering probably. To the east the German police helicopters, with callsign HUMMEL. - B = Commercial helicopter flights. They mostly start from airfied Den Helder, flying personell to offshore rigs - C = Emergency medical flights. With callsign LIFELN (lifeliner), these helicopters are stationed in Amsterdam, Groningen, Rotterdam and Eindhoven. - D = Aerial photography. To capture the landscape below, these flights often have dense tracks flying back and forth. - E = Coast Guard, with callsign NCG - F = Military. In april a Boeing E-3 Sentry departed from NATO Air Base Geilenkirchen with probably a surveillance training mission.\nAnd the blues represent our flagship carrier KLM!\nIf you want you can download the higher resolution images\n\n\n\n\n\n\nTip\n\n\n\nThanks to OpenSky, Datashader and some wonderful tutorials on the internet, e.g.¬†US Census and PyViz. I used code from these examples as well.\n\n\n\n\n\n\n\n\nNote\n\n\n\nHere you can find my other posts"
  },
  {
    "objectID": "posts/housing/2020-07-26-housing.html",
    "href": "posts/housing/2020-07-26-housing.html",
    "title": "Predicting the value of a house",
    "section": "",
    "text": "Recently I‚Äôve made my way into Kaggle. If it‚Äôs new for you, I highly recommend checking it out. Kaggle is a platform where organizations host data science competitions. They come up with a data science challenge, make the data available to Kaggle users, and many data scientist worldwide compete to get the highest score on the leaderboard. After a defined period the competition ends and the winner is awarded with a (monetary) price.\nParticipants also share their code (kernels), and have discussions on the data. This makes it an excellent platform to learn. The competitions can be a bit intimidating, since it can have extremely large datasets (100GB upwards), the objectives can be challenging (imaging, audio, text, combinations) and figuring out how to submit is not always trivial. But of course you can start with simpler competitions such as the classic Titanic example.\nSince I‚Äôm quite familiar with tabular data I decided to give the housing competition a try. The training data consists of many features describing about 1500 houses and their selling price. After numerous experiments I ended up with a top 3% score on the leaderboard before throwing in the proverbial towel. The rush of inching up the leaderboard made it a great experience!\nAfterwards I wrote about the main insights, learnings and questions\nNext up: probably a imaging competition with Pytorch or fast.ai"
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html",
    "href": "posts/mol/2019-01-12-widm.html",
    "title": "Wie is de Mol",
    "section": "",
    "text": "Wie is de Mol is enorm populair in Nederland. We zijn inmiddels toe aan het 19e seizoen. Dat betekent dat we langzamerhand ook behoorlijk wat data tot onze beschikking krijgen en er data analyse op kunnen loslaten. Het blijkt een hele leuke dataset te zijn en gaandeweg kwamen er veel interessante vragen naar boven. Ik hoop een aantal WidM vragen te beantwoorden en je misschien ook enthousiast te maken voor data science. Als input heb ik informatie van de site gebruikt, die veel informatie bijhoudt. Leuk om ook eens op te kijken. Dank hiervoor Ronald!\nEn uiteindelijk behandelen we ook de hamvraag, kunnen we het voorspellen: Wie Is De Mol?\nVeel leesplezier!\n\nVoor de data-fans, onderaan staat een link naar GitHub om de code in een Jupyter Notebook te downloaden.\nVoor de niet data-fans, je kan ook meteen naar beneden scrollen voor de eindconclusies\n\n\n\nVoor als je WidM niet kent: het spel start met ongeveer 10 deelnemers. Een van hen is de mol. De deelnemers krijgen opdrachten om geld te verdienen, maar weten dus niet wie de mol is. De mol probeert ervoor te zorgen dat het team weinig geld verdient met de opdrachten.\nElke aflevering is er een stemronde, waarin deelnemers vragen over de mol krijgen. Degene met de meeste fouten moet het spel verlaten. De mol blijft altijd in het spel. Uiteindelijk blijven er nog 3 deelnemers over: de mol en twee deelnemers. De deelnemers krijgen weer vragen over de mol. Degene met het meeste goed is de winnaar. De andere noemen we de verliezer, maar deze is wel ver gekomen! De winnaar verdient de pot.\n\n\n\nEven een opwarmertje, en voor AVRO/TROS belangrijk: hoe populair is het programma? In onderstaande grafiek zie je de kijkcijfers van de meest populaire aflevering, per seizoen. Begon het programma nog met 1 miljoen kijkers, inmiddels zitten we aan meer dan 3 miljoen. Dit lijkt momenteel ook het maximum te zijn.\n\n\n\n\n\n\n\n\n\n\n\n\nElke aflevering krijgen we sommige verdenkingen van deelnemers te zien. Als er heel weinig verdenkingen tijdens de aflevering worden gedeeld kunnen we waarschijnlijk niet hele betrouwbare conclusies trekken. We maken een grafiek waarin we berekenen hoeveel procent van de verdenkingen bekend is. 1 betekent dat we alle verdenkingen van alle deelnemers weten. De verdenkingen van de mol nemen we nu nog niet mee, die heeft natuurlijk hele andere motieven om iemand te ‚Äòverdenken‚Äô.\nHet lijkt erop dat we als tv kijker iets minder te zien krijgen. Lag tot en met seizoen 9 het percentage nog rond de 80%, tegenwoordig moeten we het met 60% doen. Seizoen 5 en 12 zijn sowieso gekke uitschieters. Dit betekent dat we over deze seizoenen waarschijnlijk niet veel kunnen zeggen.\n\n\n\n\n\n\n\n\n\n\n\n\nAls deelnemers geen idee hebben wie de mol is zullen ze gokken. Door dit gokgedrag verwachten we dat elk seizoen de mol toevallig een aantal verdenkingen door gokkers op zich krijgt. Het aantal ‚Äògokverdenkingen‚Äô verschilt per seizoen omdat het verschilt hoeveel verdenkingen de tv makers ons laten zien (de grafiek hierboven).\nIn onderstaande grafiek zie je per seizoen hoeveel ‚Äòstemmen‚Äô de mol heeft gekregen, en hoeveel we hadden verwacht op basis van gokken. Als de gele lijn boven de blauwe lijn komt is de mol verdacht en andersom.\nNico uit seizoen 2 en Margriet uit seizoen 15 zijn behoorlijk verdacht. Maar de meest verdachte mol is toch wel Jon, uit seizoen 9. Zowel Anniek, Dennis als Vivienne hadden hem al vrij snel in de smiezen.\nTegelijkertijd zijn er ook een paar niet verdachte mollen in een seizoen waar er wel veel geld uit de pot is gehaald: seizoen 6 (Milouska), 8 (Dennis) en 17 (Thomas).\n\n\n\n\n\n\n\n\n\n\n\n\nEen veelgehoorde trend is dat er steeds meer gemold wordt door kandidaten die niet de mol zijn. We kunnen dit onderzoeken door te kijken hoe verdacht de winnaar en de verliezer zijn. Terzijde: dit kan natuurlijk ook te maken hebben met hoe verdacht de mol was (verdachte mol = niet verdachte winnaar).\nEens kijken naar de winnaar, in hoeverre hij/zij de aandacht op zich wisten te vestigen. Natuurlijk verwacht je altijd wel een paar verdenkingen op je te krijgen, dus het wordt pas verdacht als je hier boven zit. Het beste voorbeeld hiervan zien we in seizoen 14, waarin Sofie veel meer verdenkingen op zich kreeg dan verwacht. Ook afgelopen seizoen 18 was Ruben een verdachte winnaar.\nToch vind ik het knapper als je kan winnen zonder verdacht te zijn. Bijvoorbeeld seizoen 9 en 12 waarin het heel duidelijk was dat de winnaar een hardwerkende deelnemer was. Complimenten Vivi√´nne en Hadewych!\n\n\n\n\n\n\n\n\n\n\n\n\nHetzelfde plaatje voor de verliezers. Zoals je hieronder ziet is de verliezer vaak een stuk minder verdacht dan de winnaar: de blauwe lijntjes liggen vaak boven de gele. Ook afgelopen seizoen was Olcay overduidelijk niet de mol.\nUitzondering die de regel bevestigt is seizoen 4, waarin Chandrika zeer verdacht was, maar het uiteindelijk Elise was die echt de mol was.\n\n\n\n\n\n\n\n\n\n\n\n\nDe deelnemers maken elke aflevering een test, waarbij ze vragen over de mol moeten beantwoorden. Soms geven ze ook aan wie ze verdenken. Maar in hoeverre weten de deelnemers wie de mol is, of wordt er maar wat gegokt? Het lijkt logisch dat er op het begin wordt gegokt en dat er uiteindelijk een beter beeld ontstaat wie de mol is. Laten we kijken hoe goed de uiteindelijke winnaar en verliezer weten te voorspellen wie de mol is.\nEn inderdaad, op het begin van het spel, als er nog veel deelnemers zijn doen de winnaars en verliezers het ongeveer even goed als puur gokken. Dit blijft zo, totdat er nog 4 deelnemers zijn. We zien dat de verliezers het ongeveer even goed blijft doen als gokken, maar de winnaars gaan het veel beter doen. Als er nog 2 deelnemers over zijn (winnaar en verliezer) heeft de winnaar het altijd goed. In de helft van de 18 seizoenen hebben we we hier informatie over. We weten dus niet zeker of het in de andere helft van de seizoenen ook zo was want dat hebben de tv-makers ons niet laten zien.\nMaar toch, 100% score: indrukwekkend!\n\n\n\n\n\n\n\n\n\n\n\n\nOp basis van bovenstaande grafiek zou je zeggen dat het vrij gemakkelijk is om de mol te ontmaskeren: gewoon luisteren naar de winnaar! Alleen, wie de winnaar is dat weten we pas achteraf. Daarom moeten we nu ook de verdenkingen van de mol meenemen in de verdenkingen. Als je naar alle seizoenen kijkt krijgen zowel de mol en de winnaar iets meer verdenkingen dan verwacht. De verliezer is iets minder verdacht.\n\n\n\n\n\n\n\n\n\nOnderstaande grafiek geeft aan hoe verdacht de mol winnaar en verliezer waren. Verdachtheid meten we met het aantal verdenkingen die iemand meer heeft gekregen dan je op basis van toeval zou verwachten. We hebben net ook gezien dat de deelnemers pas bij 4 of minder spelers in het spel meer kans hebben om goed te verdenken dan toeval, dus we kijken alleen naar de verdenkingen in de laatste paar rondes. We zien dat over het algemeen de mol het meest verdacht is.\nDe laatste jaren zien we toch meer molgedrag bij de winnaar en is de winnaar meer verdacht dan de verliezer. In 8 van de 18 seizoenen is de mol degene met het meeste stemmen.\nHeel duidelijk is dat de verliezer bijna nooit het meest verdacht is, dit is maar 1 keer voorgekomen (seizoen 3).\n\n\n\n\n\n\n\n\n\nIn een uiterste poging heb ik nog geprobeerd om het ‚Äòverdenkingsgedrag‚Äô van mol en winnaar te vergelijken. Ook heb ik gekeken naar: - Hoe vaak iemand een tunnelvisie heeft (dezelfde persoon verdenken). Mollen zijn geneigd om 3 of 4 afleveringen dezelfde persoon te verdenken, een soort fake tunnelvisie. - Hoe vaak de verdenkingen van iemand bekend worden gemaakt in de aflevering. Hier kwam geen duidelijk verschil uit tussen mollen en winnaars/verliezers. - Hoe vaak iemand zijn verdenkingen split. De winnaar deed dat iets vaker dan de mol (9 keer mol vaker, 6 keer winnaar vaker, 3 keer gelijk) - Of de mol een man of vrouw was. Het enige nuttige hierbij is wanneer er 2 mannen en 1 vrouw in de finale zitten, de mol meestal een man is (6 van de 7 keer is dit voorgekomen)\nDoor een aantal van deze elementen in een statistisch model op te nemen kon ik onderzoeken of de mol te voorspellen is. Dan kijk je dus naar alle verdenkingen en moet je van 3 deelnemers zeggen wie de mol is, bijvoorbeeld vlak voor de finaleaflevering. Uiteindelijk kon ik in 12 van de 18 seizoenen voorspellen wie de mol was, 2/3 kans dus. Toch al een stuk beter dan 1/3 gokkans, maar zeker niet altijd goed.\n\n\n\n\n\n\n\n\n\n\n\n\nWe kunnen ook kijken naar de prijzenpot. In onderstaande grafiek zie je de pot op het einde van het seizoen. De pot lijkt wel steeds kleiner te worden. komt dit doordat er minder geld valt te verdienen, zijn de opdrachten moeilijker of wordt er meer gemold)?\n\n\n\n\n\n\n\n\n\nDe totale potenti√´le pot was vooral in de eerste seizoenen erg hoog. In seizoen 3 kon er maar lieft 250.000 euro worden verdiend! Daarna het langzaam af. Bezuinigingen bij de publieke omroep? In seizoen 17 en 18 is er weer wat meer te verdienen.\n\n\n\n\n\n\n\n\n\nHet percentage van de potenti√´le pot dat wordt binnengehaald schommelt nogal, tussen de 20 en 50 procent. Dit kan natuurlijk door mollen komen, maar soms zijn er ook opdrachten waarbij geld wordt verloren uit de pot. Ik kon geen verband vinden tussen dit percentage en hoe verdacht mol of winnaar was. Misschien komt dit doordat er in sommige seizoenen ook geld kan worden verloren, of misschien is het heel persoonsafhankelijk hoe de mol opereert en hoe goed het team functioneert in geld binnenhalen.\nEigenlijk zijn de winnaar in seizoen 1 (Petra), 2 (Sigrid) en 9 (Hadewych) het meest succesvol geweest. Ze waren ook minder verdacht dan verwacht, dus(?) niet aan het mollen.\nDe meest succesvolle mol is wat lastiger maar ik neig naar Anne-Marie uit seizoen 12: niet verdacht, wel een kleine pot. Maar seizoen 3, 4, 5 en 7 waren ook prima!\n\n\n\n\n\n\n\n\n\n\n\n\n\nEr zitten grote verschillen tussen de seizoenen in hoe verdacht de mol, de winnaar en de verliezer zijn\nDe winnaar weet vrijwel altijd wie de mol is, maar weet het pas de laatste paar afleveringen\nDe verliezer weet meestal niet wie de mol is en had net zo goed kop of munt kunnen gokken\nDe mol wordt eigenlijk alleen door de winnaar ontmaskerd\nDe prijzenpot voor WidM is gedaald\nWe kunnen geen relatie vinden tussen het percentage van de pot die wordt binnengehaald en het mate van verdenking op mol of winnaar\nWe kunnen op basis van de verdenkingen in de finale iets beter voorspellen wie de mol is (12 van de 18 seizoenen goed voorspeld)\nVoor de toekomst kan het leuk zijn om de verdenkingen van het publiek via de mol-app te bekijken. Doen de tv kijkers het beter of wordt er maar wat gegokt en krijgen we eigenlijk te weinig echte hints?\n\nWelke vragen heb je zelf nog? Veel plezier met Wie is de Mol dit seizoen!\nHier kan je de jupyter notebook downloaden: https://github.com/jvanelteren/wie_is_de_mol\nMocht je data science leuk vinden kan ik je van harte aanraden om eens een gratis online Python programmeercursus te volgen!"
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html#korte-uitleg",
    "href": "posts/mol/2019-01-12-widm.html#korte-uitleg",
    "title": "Wie is de Mol",
    "section": "",
    "text": "Voor als je WidM niet kent: het spel start met ongeveer 10 deelnemers. Een van hen is de mol. De deelnemers krijgen opdrachten om geld te verdienen, maar weten dus niet wie de mol is. De mol probeert ervoor te zorgen dat het team weinig geld verdient met de opdrachten.\nElke aflevering is er een stemronde, waarin deelnemers vragen over de mol krijgen. Degene met de meeste fouten moet het spel verlaten. De mol blijft altijd in het spel. Uiteindelijk blijven er nog 3 deelnemers over: de mol en twee deelnemers. De deelnemers krijgen weer vragen over de mol. Degene met het meeste goed is de winnaar. De andere noemen we de verliezer, maar deze is wel ver gekomen! De winnaar verdient de pot."
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html#kijkcijfers",
    "href": "posts/mol/2019-01-12-widm.html#kijkcijfers",
    "title": "Wie is de Mol",
    "section": "",
    "text": "Even een opwarmertje, en voor AVRO/TROS belangrijk: hoe populair is het programma? In onderstaande grafiek zie je de kijkcijfers van de meest populaire aflevering, per seizoen. Begon het programma nog met 1 miljoen kijkers, inmiddels zitten we aan meer dan 3 miljoen. Dit lijkt momenteel ook het maximum te zijn."
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html#welke-informatie-is-beschikbaar",
    "href": "posts/mol/2019-01-12-widm.html#welke-informatie-is-beschikbaar",
    "title": "Wie is de Mol",
    "section": "",
    "text": "Elke aflevering krijgen we sommige verdenkingen van deelnemers te zien. Als er heel weinig verdenkingen tijdens de aflevering worden gedeeld kunnen we waarschijnlijk niet hele betrouwbare conclusies trekken. We maken een grafiek waarin we berekenen hoeveel procent van de verdenkingen bekend is. 1 betekent dat we alle verdenkingen van alle deelnemers weten. De verdenkingen van de mol nemen we nu nog niet mee, die heeft natuurlijk hele andere motieven om iemand te ‚Äòverdenken‚Äô.\nHet lijkt erop dat we als tv kijker iets minder te zien krijgen. Lag tot en met seizoen 9 het percentage nog rond de 80%, tegenwoordig moeten we het met 60% doen. Seizoen 5 en 12 zijn sowieso gekke uitschieters. Dit betekent dat we over deze seizoenen waarschijnlijk niet veel kunnen zeggen."
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html#hoe-verdacht-is-de-mol",
    "href": "posts/mol/2019-01-12-widm.html#hoe-verdacht-is-de-mol",
    "title": "Wie is de Mol",
    "section": "",
    "text": "Als deelnemers geen idee hebben wie de mol is zullen ze gokken. Door dit gokgedrag verwachten we dat elk seizoen de mol toevallig een aantal verdenkingen door gokkers op zich krijgt. Het aantal ‚Äògokverdenkingen‚Äô verschilt per seizoen omdat het verschilt hoeveel verdenkingen de tv makers ons laten zien (de grafiek hierboven).\nIn onderstaande grafiek zie je per seizoen hoeveel ‚Äòstemmen‚Äô de mol heeft gekregen, en hoeveel we hadden verwacht op basis van gokken. Als de gele lijn boven de blauwe lijn komt is de mol verdacht en andersom.\nNico uit seizoen 2 en Margriet uit seizoen 15 zijn behoorlijk verdacht. Maar de meest verdachte mol is toch wel Jon, uit seizoen 9. Zowel Anniek, Dennis als Vivienne hadden hem al vrij snel in de smiezen.\nTegelijkertijd zijn er ook een paar niet verdachte mollen in een seizoen waar er wel veel geld uit de pot is gehaald: seizoen 6 (Milouska), 8 (Dennis) en 17 (Thomas)."
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html#zijn-winnaars-vaak-aan-het-mollen",
    "href": "posts/mol/2019-01-12-widm.html#zijn-winnaars-vaak-aan-het-mollen",
    "title": "Wie is de Mol",
    "section": "",
    "text": "Een veelgehoorde trend is dat er steeds meer gemold wordt door kandidaten die niet de mol zijn. We kunnen dit onderzoeken door te kijken hoe verdacht de winnaar en de verliezer zijn. Terzijde: dit kan natuurlijk ook te maken hebben met hoe verdacht de mol was (verdachte mol = niet verdachte winnaar).\nEens kijken naar de winnaar, in hoeverre hij/zij de aandacht op zich wisten te vestigen. Natuurlijk verwacht je altijd wel een paar verdenkingen op je te krijgen, dus het wordt pas verdacht als je hier boven zit. Het beste voorbeeld hiervan zien we in seizoen 14, waarin Sofie veel meer verdenkingen op zich kreeg dan verwacht. Ook afgelopen seizoen 18 was Ruben een verdachte winnaar.\nToch vind ik het knapper als je kan winnen zonder verdacht te zijn. Bijvoorbeeld seizoen 9 en 12 waarin het heel duidelijk was dat de winnaar een hardwerkende deelnemer was. Complimenten Vivi√´nne en Hadewych!"
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html#en-verliezers",
    "href": "posts/mol/2019-01-12-widm.html#en-verliezers",
    "title": "Wie is de Mol",
    "section": "",
    "text": "Hetzelfde plaatje voor de verliezers. Zoals je hieronder ziet is de verliezer vaak een stuk minder verdacht dan de winnaar: de blauwe lijntjes liggen vaak boven de gele. Ook afgelopen seizoen was Olcay overduidelijk niet de mol.\nUitzondering die de regel bevestigt is seizoen 4, waarin Chandrika zeer verdacht was, maar het uiteindelijk Elise was die echt de mol was."
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html#kunnen-deelnemers-de-mol-ontmaskeren",
    "href": "posts/mol/2019-01-12-widm.html#kunnen-deelnemers-de-mol-ontmaskeren",
    "title": "Wie is de Mol",
    "section": "",
    "text": "De deelnemers maken elke aflevering een test, waarbij ze vragen over de mol moeten beantwoorden. Soms geven ze ook aan wie ze verdenken. Maar in hoeverre weten de deelnemers wie de mol is, of wordt er maar wat gegokt? Het lijkt logisch dat er op het begin wordt gegokt en dat er uiteindelijk een beter beeld ontstaat wie de mol is. Laten we kijken hoe goed de uiteindelijke winnaar en verliezer weten te voorspellen wie de mol is.\nEn inderdaad, op het begin van het spel, als er nog veel deelnemers zijn doen de winnaars en verliezers het ongeveer even goed als puur gokken. Dit blijft zo, totdat er nog 4 deelnemers zijn. We zien dat de verliezers het ongeveer even goed blijft doen als gokken, maar de winnaars gaan het veel beter doen. Als er nog 2 deelnemers over zijn (winnaar en verliezer) heeft de winnaar het altijd goed. In de helft van de 18 seizoenen hebben we we hier informatie over. We weten dus niet zeker of het in de andere helft van de seizoenen ook zo was want dat hebben de tv-makers ons niet laten zien.\nMaar toch, 100% score: indrukwekkend!"
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html#wie-is-de-mol",
    "href": "posts/mol/2019-01-12-widm.html#wie-is-de-mol",
    "title": "Wie is de Mol",
    "section": "",
    "text": "Op basis van bovenstaande grafiek zou je zeggen dat het vrij gemakkelijk is om de mol te ontmaskeren: gewoon luisteren naar de winnaar! Alleen, wie de winnaar is dat weten we pas achteraf. Daarom moeten we nu ook de verdenkingen van de mol meenemen in de verdenkingen. Als je naar alle seizoenen kijkt krijgen zowel de mol en de winnaar iets meer verdenkingen dan verwacht. De verliezer is iets minder verdacht.\n\n\n\n\n\n\n\n\n\nOnderstaande grafiek geeft aan hoe verdacht de mol winnaar en verliezer waren. Verdachtheid meten we met het aantal verdenkingen die iemand meer heeft gekregen dan je op basis van toeval zou verwachten. We hebben net ook gezien dat de deelnemers pas bij 4 of minder spelers in het spel meer kans hebben om goed te verdenken dan toeval, dus we kijken alleen naar de verdenkingen in de laatste paar rondes. We zien dat over het algemeen de mol het meest verdacht is.\nDe laatste jaren zien we toch meer molgedrag bij de winnaar en is de winnaar meer verdacht dan de verliezer. In 8 van de 18 seizoenen is de mol degene met het meeste stemmen.\nHeel duidelijk is dat de verliezer bijna nooit het meest verdacht is, dit is maar 1 keer voorgekomen (seizoen 3).\n\n\n\n\n\n\n\n\n\nIn een uiterste poging heb ik nog geprobeerd om het ‚Äòverdenkingsgedrag‚Äô van mol en winnaar te vergelijken. Ook heb ik gekeken naar: - Hoe vaak iemand een tunnelvisie heeft (dezelfde persoon verdenken). Mollen zijn geneigd om 3 of 4 afleveringen dezelfde persoon te verdenken, een soort fake tunnelvisie. - Hoe vaak de verdenkingen van iemand bekend worden gemaakt in de aflevering. Hier kwam geen duidelijk verschil uit tussen mollen en winnaars/verliezers. - Hoe vaak iemand zijn verdenkingen split. De winnaar deed dat iets vaker dan de mol (9 keer mol vaker, 6 keer winnaar vaker, 3 keer gelijk) - Of de mol een man of vrouw was. Het enige nuttige hierbij is wanneer er 2 mannen en 1 vrouw in de finale zitten, de mol meestal een man is (6 van de 7 keer is dit voorgekomen)\nDoor een aantal van deze elementen in een statistisch model op te nemen kon ik onderzoeken of de mol te voorspellen is. Dan kijk je dus naar alle verdenkingen en moet je van 3 deelnemers zeggen wie de mol is, bijvoorbeeld vlak voor de finaleaflevering. Uiteindelijk kon ik in 12 van de 18 seizoenen voorspellen wie de mol was, 2/3 kans dus. Toch al een stuk beter dan 1/3 gokkans, maar zeker niet altijd goed."
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html#money-money-money",
    "href": "posts/mol/2019-01-12-widm.html#money-money-money",
    "title": "Wie is de Mol",
    "section": "",
    "text": "We kunnen ook kijken naar de prijzenpot. In onderstaande grafiek zie je de pot op het einde van het seizoen. De pot lijkt wel steeds kleiner te worden. komt dit doordat er minder geld valt te verdienen, zijn de opdrachten moeilijker of wordt er meer gemold)?\n\n\n\n\n\n\n\n\n\nDe totale potenti√´le pot was vooral in de eerste seizoenen erg hoog. In seizoen 3 kon er maar lieft 250.000 euro worden verdiend! Daarna het langzaam af. Bezuinigingen bij de publieke omroep? In seizoen 17 en 18 is er weer wat meer te verdienen.\n\n\n\n\n\n\n\n\n\nHet percentage van de potenti√´le pot dat wordt binnengehaald schommelt nogal, tussen de 20 en 50 procent. Dit kan natuurlijk door mollen komen, maar soms zijn er ook opdrachten waarbij geld wordt verloren uit de pot. Ik kon geen verband vinden tussen dit percentage en hoe verdacht mol of winnaar was. Misschien komt dit doordat er in sommige seizoenen ook geld kan worden verloren, of misschien is het heel persoonsafhankelijk hoe de mol opereert en hoe goed het team functioneert in geld binnenhalen.\nEigenlijk zijn de winnaar in seizoen 1 (Petra), 2 (Sigrid) en 9 (Hadewych) het meest succesvol geweest. Ze waren ook minder verdacht dan verwacht, dus(?) niet aan het mollen.\nDe meest succesvolle mol is wat lastiger maar ik neig naar Anne-Marie uit seizoen 12: niet verdacht, wel een kleine pot. Maar seizoen 3, 4, 5 en 7 waren ook prima!"
  },
  {
    "objectID": "posts/mol/2019-01-12-widm.html#conclusies",
    "href": "posts/mol/2019-01-12-widm.html#conclusies",
    "title": "Wie is de Mol",
    "section": "",
    "text": "Er zitten grote verschillen tussen de seizoenen in hoe verdacht de mol, de winnaar en de verliezer zijn\nDe winnaar weet vrijwel altijd wie de mol is, maar weet het pas de laatste paar afleveringen\nDe verliezer weet meestal niet wie de mol is en had net zo goed kop of munt kunnen gokken\nDe mol wordt eigenlijk alleen door de winnaar ontmaskerd\nDe prijzenpot voor WidM is gedaald\nWe kunnen geen relatie vinden tussen het percentage van de pot die wordt binnengehaald en het mate van verdenking op mol of winnaar\nWe kunnen op basis van de verdenkingen in de finale iets beter voorspellen wie de mol is (12 van de 18 seizoenen goed voorspeld)\nVoor de toekomst kan het leuk zijn om de verdenkingen van het publiek via de mol-app te bekijken. Doen de tv kijkers het beter of wordt er maar wat gegokt en krijgen we eigenlijk te weinig echte hints?\n\nWelke vragen heb je zelf nog? Veel plezier met Wie is de Mol dit seizoen!\nHier kan je de jupyter notebook downloaden: https://github.com/jvanelteren/wie_is_de_mol\nMocht je data science leuk vinden kan ik je van harte aanraden om eens een gratis online Python programmeercursus te volgen!"
  },
  {
    "objectID": "posts/moties/2021-03-07-kamermoties_topics.html",
    "href": "posts/moties/2021-03-07-kamermoties_topics.html",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "",
    "text": "Nog net voor de verkiezingen deel 2 van het motie-onderzoek! Naast deze blog heb ik ook nog de StemVinder ontwikkeld om snel relevante moties te vinden.\nIn dit deel kijk ik naar de inhoud van de moties. Op de moties te clusteren naar onderwerp gebruikte ik in eerste instantie een bekende techniek Latent Dirichlet Allocation, maar via een gelukkig toeval kwam ik achter een gloednieuwe aanpak die veel beter werkt! Longhow Lam heeft deze toegepast op kamerdebatten van de Tweede Kamer.\nHet Top2Vec algoritme probeert soortgelijke woorden en documenten te clusteren en hieruit onderwerpen te destilleren. In de wordcloud hierboven staan heel generieke woorden die in veel moties voorkomen. Deze zijn niet onderscheidend en worden er automatisch uitgefilterd door het algoritme. Echt weer zo‚Äôn voorbeeld van een doorbraak in machine learning die sneller en beter werkt waardoor oude technieken bij het grofvuil kunnen.\nBij de moties worden er ongeveer 250 topics ge√Ødentificeerd. In deze onderwerpen zit wat overlap en het is een beetje lastig visualiseren, dus uiteindelijk heb ik die voor deze blogpost samengevoegd tot 15. Onderop deze blog staan wordclouds van de 15 onderwerpen."
  },
  {
    "objectID": "posts/moties/2021-03-07-kamermoties_topics.html#welk-soort-onderwerpen-staan-op-de-agenda",
    "href": "posts/moties/2021-03-07-kamermoties_topics.html#welk-soort-onderwerpen-staan-op-de-agenda",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "Welk soort onderwerpen staan op de agenda?",
    "text": "Welk soort onderwerpen staan op de agenda?\nEerst kijken we naar de ontwikkeling van de onderwerpen van de ingediende moties. We weten al dat het absoluut aantal moties stijgt, dus heb ik gekeken naar de relatieve verdeling van de onderwerpen.\n\n\n\n\n\n\n\nOpvallend dat de verhoudingen redelijk stabiel zijn! Je ziet dat in de loop van de tijd klimaat en energie, milieu en regelgeving (heel veel coronaregels zitten hier ook in gecategoriseerd), sociale zaken en wonen omhoog gaan. Omlaag gaan landbouw en dierenwelzijn, natuur en gaswinning, onderwijs en openbaar vervoer. Binnen de onderwerpen zijn natuurlijk wel verschuivingen waar het precies over gaat. We onderzoeken nu de ingediende moties tijdens de afgelopen Tweede Kamer periode."
  },
  {
    "objectID": "posts/moties/2021-03-07-kamermoties_topics.html#meest-actieve-partijen-per-onderwerp",
    "href": "posts/moties/2021-03-07-kamermoties_topics.html#meest-actieve-partijen-per-onderwerp",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "Meest actieve partijen per onderwerp",
    "text": "Meest actieve partijen per onderwerp\nWe onderzoeken welke partijen het meest actief zijn door op drie manieren naar de data te kijken:\n\nAantal ingediende moties (per partij per onderwerp)\nAantal succesvolle moties\nAantal succesvolle moties per zetel\n\n\n\n\n\n\n\n\nIn bovenstaande grafiek zien we bijvoorbeeld dat op onderwijs de meeste moties worden ingediend door Groenlinks (1 in de grafiek), gevolgd door de SP (2), PvdA (3) en D66 (4). Een punt van aandacht is dat deze analyse niet aangeeft wat de partijen met de moties willen bereiken, bijvoorbeeld op openbaar vervoer wil VVD waarschijnlijk heel iets anders bereiken dan SP.\nPVV is erg actief op justitie, en de PvdD op klimaat, dierenwelzijn milieu en natuur. Ook de enorme output van de SP valt op! Maar ingediend is niet hetzelfde als aangenomen, dat wordt de volgende grafiek:\n\n\n\n\n\n\n\nWat betreft het aantal succesvolle moties dan zien we daar ineens vier partijen bovendrijven: CDA, D66, GroenLinks en de VVD. Veel regeringspartijen, dat is logisch want die hebben een meerderheid. Ook vind ik het opvallend dat PvdA echt op sociale zaken en het pensioenstelsel succesvol is en GroenLinks op de andere onderwerpen.\nNu kijken we naar het aantal succesvolle moties per zetel\n\n\n\n\n\n\n\nMet je stem koop je op 17 maart politieke invloed. Dit overzicht geeft weer hoeveel ‚Äòwaar je voor je geld‚Äô krijgt, hoeveel succesvolle moties een zetel van een partij er doorheen krijgt per onderwerp. Het is weer een heel ander beeld: de christelijke partijen doen het heel erg goed (even gecheckt en inderdaad het Dik-Faber effect bij de ChristenUnie op Zorg, Voordewind op Buitenlandse zaken) en de SP komt een stuk minder terug. Opvallend ook dat D66 relatief weinig scoort op Onderwijs. Partijen die minder in de prijzen vallen zijn FvD (nr 5 op Europese Unie), de PVV nergens en de VVD op financiele sector (nr 5). Bij de VVD is dit te verklaren doordat ze veel zetels bekleedt."
  },
  {
    "objectID": "posts/moties/2021-03-07-kamermoties_topics.html#waar-richten-de-partijen-zich-op",
    "href": "posts/moties/2021-03-07-kamermoties_topics.html#waar-richten-de-partijen-zich-op",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "Waar richten de partijen zich op?",
    "text": "Waar richten de partijen zich op?\nIn bovenstaande grafieken hebben we de partijen onderling vergeleken. Nu kijken we per partij op welk vlak ze het meest actief zijn\n\n\n\n\n\n\n\nAls een partij een aantal heel grote bollen heeft betekent dit dat de partij zich heel erg richt op dit onderwerp. Zijn er geen grote bollen binnen een partij is de inzet meer over de onderwerpen verspreid. Algemene zaken, Onderwijs en Zorg krijgen bij veel partijen veel aandacht. Daarnaast hebben FvD, PVV, 50PLUS en de PvdD een heel uitgesproken profiel. In het achterliggende notebook heb ik ook nog gekeken naar de ontwikkelingen per partij van de afgelopen 4 kamerperiodes."
  },
  {
    "objectID": "posts/moties/2021-03-07-kamermoties_topics.html#ontwikkeling-per-partij",
    "href": "posts/moties/2021-03-07-kamermoties_topics.html#ontwikkeling-per-partij",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "Ontwikkeling per partij",
    "text": "Ontwikkeling per partij"
  },
  {
    "objectID": "posts/moties/2021-03-07-kamermoties_topics.html#stemgedrag-per-onderwerp",
    "href": "posts/moties/2021-03-07-kamermoties_topics.html#stemgedrag-per-onderwerp",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "Stemgedrag per onderwerp",
    "text": "Stemgedrag per onderwerp\nDan toch nog eens proberen het stemgedrag te visualiseren. Als de VVD iets indient voor de Financiele Sector betekent dit namelijk iets heel anders dan als de SP dat doet. In onderstaande plots staat per onderwerp het stemgedrag gevisualiseerd. Positief of negatief zegt niets, het gaat om partijen die dichtbij of ver weg van elkaar staan. PvdD en VVD vormen meestal de uitersten en verschillen dus het meeste op stemgedrag. Deze grafieken verklaren meestal zo‚Äôn 35%-55% van de variatie in het stemgedrag. Let op: het is dus een versimpeling van de werkelijkheid!\n\n\n\n\n\n\n\n‚Äò#‚Äô geeft het aantal moties aan en ‚Äò%‚Äô het percentage dat deze visualisatie verklaart. Het meest opvallend is dat FvD en PVV soms in het midden zitten en soms aan de rechterkant. Bij de Europese Unie mengen SP, PvdD en de SGP zich hier ook in. Als het gaat om pensioenen zitten ze juist meer aan de linkerkant. De groep PvdD, SP, GroenLinks, PvdA en DENK zit standaard links, alleen wederom bij de EU en pensioenstelsel wordt gehusseld. 50PLUS zit vaak in het midden, behalve bij pensioenstelsel."
  },
  {
    "objectID": "posts/moties/2021-03-07-kamermoties_topics.html#onderzoek-naar-klimaat",
    "href": "posts/moties/2021-03-07-kamermoties_topics.html#onderzoek-naar-klimaat",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "Onderzoek naar klimaat",
    "text": "Onderzoek naar klimaat\nOmdat ik denk dat klimaat de grootste uitdaging is voor de mensheid heb ik hier de subonderwerpen nog eens doorgenomen. Natuur en milieu zijn natuurlijk ook heel erg belangrijke onderwerpen, maar toch besloten het even bij het klimaat te houden.\n\n\n\n\n\n\n\nDe vraag is op welke partij je stemt: PvdD dient enorm veel moties in en bepaalt hier wel het debat mee. Maar D66 en GroenLinks dienen dan weer meer succesvolle moties in.\nEn hier houdt het een beetje op, voor een stemadvies moet je namelijk uiteindelijk toch weten waar de partijen voor staan. Laat ik daar nu net de StemVinder voor hebben gemaakt. Veel plezier ermee!\n\n\n\n\n\n\nTip\n\n\n\nBedankt Dimo Angelov, bedenker en ontwikkelaar van Top2Vec, Longhow Lam voor de LinkedIn blogpost en Willem Glasbergen voor de tip! Zonder deze drie was het niet gelukt :-)"
  },
  {
    "objectID": "posts/moties/2021-03-07-kamermoties_topics.html#bijlage-classificering-van-de-onderwerpen",
    "href": "posts/moties/2021-03-07-kamermoties_topics.html#bijlage-classificering-van-de-onderwerpen",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "Bijlage: classificering van de onderwerpen",
    "text": "Bijlage: classificering van de onderwerpen"
  },
  {
    "objectID": "posts/moties2023/2023-09-23-kamermoties_topics.html",
    "href": "posts/moties2023/2023-09-23-kamermoties_topics.html",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "",
    "text": "Deel 2 van het motie-onderzoek!\nWe kijken naar de onderwerpen waar de ingediende moties van afgelopen Kamerperiode over gaan. Top2Vec is een algoritme dat de moties kan clusteren naar onderwerp. Uiteindelijk zijn alle moties aan 82 onderwerpen toegewezen. Voor deze blog heb ik deze onderwerpen weer verder gegroepeerd naar 14 hoofdonderwerpen.\nWe onderzoeken de partijen en onderwerpen door op drie manieren naar de data te kijken:\nOnderstaande figuur geeft aan welke partijen het meeste moties indienen per onderwerp:\nVoor het onderwerp ‚ÄòLandbouw en Milieu‚Äô dient de PvDD het meeste moties in, gevolgd door BBB, D66 en GroenLinks. De standpunten van de partijen kunnen natuurlijk verschillen!\nMaar het aantal ingediende moties is niet hetzelfde als het aantal aangenomen moties, dat laat de volgende figuur zien:\nAls we kijken naar succesvolle moties dan zien we daar ineens vier partijen bovendrijven: CDA, ChristenUnie, D66 en VVD. De regeringspartijen, dat is logisch want die hebben een meerderheid.\nNu kijken we naar het aantal succesvolle moties per zetel:\nDit overzicht geeft weer hoeveel moties van een partij worden aangenomen per onderwerp per zetel. Het is weer een heel ander beeld: partijen als BBB, CU en DENK doen het goed. Dit zijn natuurlijk ook partijen met weinig zetels."
  },
  {
    "objectID": "posts/moties2023/2023-09-23-kamermoties_topics.html#waar-richten-de-partijen-zich-op",
    "href": "posts/moties2023/2023-09-23-kamermoties_topics.html#waar-richten-de-partijen-zich-op",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "Waar richten de partijen zich op?",
    "text": "Waar richten de partijen zich op?\nIn bovenstaande grafieken hebben we de partijen onderling vergeleken. Nu kijken we per partij op welk vlak ze het meest actief zijn\n\n\n\n\n\n\n\n\nAls een partij een hele grote bol heeft betekent dit dat de partij zich heel erg richt op dit onderwerp. Zoals bijvoorbeeld Volt op Europa. Als een partij grote bollen heeft dan is er geen duidelijk speerpunt en zijn de moties meer verspreid."
  },
  {
    "objectID": "posts/moties2023/2023-09-23-kamermoties_topics.html#stemgedrag-op-klimaat",
    "href": "posts/moties2023/2023-09-23-kamermoties_topics.html#stemgedrag-op-klimaat",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "Stemgedrag op klimaat",
    "text": "Stemgedrag op klimaat\nHieronder zie je het stemgedrag op klimaat. De afstand tussen de partijen geeft aan hoeveel ze verschillen. Hiermee kunnen we ~40% van het stemgedrag verklaren.\n\n\n\n\n\n\n\n\nAls we er nog een tweede as bij zetten kunnen we 60% van de variatie verklaren:\n\n\n\n\n\n\n\n\nHet lijkt me vooral interessant wat de standpunten van Omtzigt zijn ten opzichte van klimaat. Dit zou zomaar eens kunnen bepalen welke kant het beleid op gaat kantelen.\nOm gemakkelijk de moties te doorzoeken heb ik de MotieMachine gemaakt. Hier staan alle 82 onderwerpen in, inclusief een mogelijkheid om de moties door te lezen. Veel plezier ermee!"
  },
  {
    "objectID": "posts/moties2023/2023-09-23-kamermoties_topics.html#bijlage-wordclouds-van-de-14-onderwerpen",
    "href": "posts/moties2023/2023-09-23-kamermoties_topics.html#bijlage-wordclouds-van-de-14-onderwerpen",
    "title": "Tekst analyse van Tweede Kamer moties",
    "section": "Bijlage: Wordclouds van de 14 onderwerpen",
    "text": "Bijlage: Wordclouds van de 14 onderwerpen"
  },
  {
    "objectID": "posts/row/2024-12-30-rowfun.html",
    "href": "posts/row/2024-12-30-rowfun.html",
    "title": "Rowing",
    "section": "",
    "text": "In January 2024 I tried the rowing machine, also known as the ergometer. Basically rowing indoors without ever moving a bit. Because it‚Äôs a very good body workout and less prone to injury. And the sauna afterwards is a great reward.\nSo this got a little out of control, in a good way. In total I rowed 1000 km (or 1 million meters).\n\n\n\n\n\n\n\n\n¬†\nIn April I started doing longer distances at a slower pace. End of September the goal to reach 1 million meters in a year materialized.\nSo that was tough but it was reached! Including a marathon December 14th and 100km in a week.\n¬†\n\n\n\n\n\n\n\n\n¬†\nHere you see the split times. The small dots represent the short rows. Of course the average split times are faster compared to a longer training where you go slower.\nYou can see that at the end of the year I was steadily going slower. Of course I was also rowing longer, but maybe got a bit fatigued.\nAnyway, it was fun!"
  }
]